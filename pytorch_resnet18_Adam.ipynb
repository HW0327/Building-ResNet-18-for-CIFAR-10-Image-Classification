{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0ac129-4b37-4804-8613-3b639d238c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
      "  libsqlite          conda-forge/linux-64::libsqlite-3.40.0-h753d276_0\n",
      "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4\n",
      "  toolz              conda-forge/noarch::toolz-0.12.0-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  chardet-4.0.0-py39hf3d152e_1\n",
      "  libstdcxx-ng-11.2.0-he4da1e4_9\n",
      "  six-1.16.0-pyh6c4a22f_0\n",
      "  zlib-1.2.11-h516909a_1010\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  _openmp_mutex                                   4.5-1_gnu --> 4.5-2_gnu\n",
      "  brotlipy                          0.7.0-py39h3811e60_1001 --> 0.7.0-py39hb9d737c_1005\n",
      "  ca-certificates                      2021.5.30-ha878542_0 --> 2022.9.24-ha878542_0\n",
      "  certifi            conda-forge/linux-64::certifi-2021.5.~ --> conda-forge/noarch::certifi-2022.9.24-pyhd8ed1ab_0\n",
      "  cffi                                1.14.6-py39h4bc2ebd_1 --> 1.15.1-py39he91dace_2\n",
      "  charset-normalizer                     2.0.0-pyhd8ed1ab_0 --> 2.1.1-pyhd8ed1ab_0\n",
      "  colorama                               0.4.4-pyh9f0ad1d_0 --> 0.4.6-pyhd8ed1ab_0\n",
      "  conda                               4.10.3-py39hf3d152e_2 --> 22.9.0-py39hf3d152e_2\n",
      "  conda-package-han~                   1.7.3-py39h3811e60_0 --> 1.9.0-py39hb9d737c_1\n",
      "  cryptography                         3.4.7-py39hbca0aa6_0 --> 38.0.3-py39h3ccb8fc_0\n",
      "  idna                                     3.1-pyhd3deb0d_0 --> 3.4-pyhd8ed1ab_0\n",
      "  ld_impl_linux-64                        2.36.1-hea4e1c9_2 --> 2.39-hcc3a1bd_1\n",
      "  libffi                                   3.4.2-h9c3ff4c_4 --> 3.4.2-h7f98852_5\n",
      "  libgcc-ng                               11.2.0-h1d223b6_9 --> 12.2.0-h65d4601_19\n",
      "  libgomp                                 11.2.0-h1d223b6_9 --> 12.2.0-h65d4601_19\n",
      "  ncurses                                    6.2-h58526e2_4 --> 6.3-h27087fc_1\n",
      "  openssl                                 1.1.1l-h7f98852_0 --> 3.0.7-h166bdaf_0\n",
      "  pycosat                           0.6.3-py39h3811e60_1006 --> 0.6.4-py39hb9d737c_1\n",
      "  pycparser                               2.20-pyh9f0ad1d_2 --> 2.21-pyhd8ed1ab_0\n",
      "  pyopenssl                             20.0.1-pyhd8ed1ab_0 --> 22.1.0-pyhd8ed1ab_0\n",
      "  pysocks            conda-forge/linux-64::pysocks-1.7.1-p~ --> conda-forge/noarch::pysocks-1.7.1-pyha2e5f31_6\n",
      "  python                           3.9.7-hb7a2778_2_cpython --> 3.9.13-h2660328_0_cpython\n",
      "  readline                                   8.1-h46c0cb4_0 --> 8.1.2-h0f457ee_0\n",
      "  requests                              2.26.0-pyhd8ed1ab_0 --> 2.28.1-pyhd8ed1ab_1\n",
      "  ruamel_yaml                     0.15.80-py39h3811e60_1004 --> 0.15.80-py39hb9d737c_1008\n",
      "  setuptools         conda-forge/linux-64::setuptools-58.0~ --> conda-forge/noarch::setuptools-65.5.1-pyhd8ed1ab_0\n",
      "  sqlite                                  3.36.0-h9cd32fc_2 --> 3.40.0-h4ff8645_0\n",
      "  tk                                      8.6.11-h27826a3_1 --> 8.6.12-h27826a3_0\n",
      "  tqdm                                  4.62.3-pyhd8ed1ab_0 --> 4.64.1-pyhd8ed1ab_0\n",
      "  tzdata                                   2021a-he74cb21_1 --> 2022f-h191b570_0\n",
      "  urllib3                               1.26.7-pyhd8ed1ab_0 --> 1.26.11-pyhd8ed1ab_0\n",
      "  wheel                                 0.37.0-pyhd8ed1ab_1 --> 0.38.4-pyhd8ed1ab_0\n",
      "  xz                                       5.2.5-h516909a_1 --> 5.2.6-h166bdaf_0\n",
      "  yaml                                     0.2.5-h516909a_0 --> 0.2.5-h7f98852_2\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /opt/conda\n",
      "  uid: 1000\n",
      "  gid: 100\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch-summary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda update -n base conda\n",
    "%conda install pytorch\n",
    "%conda install torchvision\n",
    "%pip install torch-summary\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe482f3-2fa2-47d3-ab9b-0e1616293a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchsummary\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "551c0cf9-162e-42d1-a813-e58d4871c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "\n",
    "# _, term_width = os.popen('stty size', 'r').read().split()\n",
    "term_width = 50\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8107b7-5d71-4168-88ad-ca44e8e1ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2688f85b-1fc7-48a0-b1f6-0373074e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb8fbf6-ee1d-4fd3-bfc1-62dd014c5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a50d30e2-ae7f-44ed-a9ef-8b6362b4066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "220ab99e-ef76-4a7e-b42f-645c29cd6b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ResNet: 1-1                            [-1, 10]                  --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 32, 32]          864\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 32, 32]          64\n",
      "|    └─Sequential: 2-3                   [-1, 32, 32, 32]          --\n",
      "|    |    └─BasicBlock: 3-1              [-1, 32, 32, 32]          18,560\n",
      "|    |    └─BasicBlock: 3-2              [-1, 32, 32, 32]          18,560\n",
      "|    └─Sequential: 2-4                   [-1, 64, 16, 16]          --\n",
      "|    |    └─BasicBlock: 3-3              [-1, 64, 16, 16]          57,728\n",
      "|    |    └─BasicBlock: 3-4              [-1, 64, 16, 16]          73,984\n",
      "|    └─Sequential: 2-5                   [-1, 128, 8, 8]           --\n",
      "|    |    └─BasicBlock: 3-5              [-1, 128, 8, 8]           230,144\n",
      "|    |    └─BasicBlock: 3-6              [-1, 128, 8, 8]           295,424\n",
      "|    └─Sequential: 2-6                   [-1, 256, 4, 4]           --\n",
      "|    |    └─BasicBlock: 3-7              [-1, 256, 4, 4]           919,040\n",
      "|    |    └─BasicBlock: 3-8              [-1, 256, 4, 4]           1,180,672\n",
      "|    └─Dropout: 2-7                      [-1, 256]                 --\n",
      "|    └─Linear: 2-8                       [-1, 10]                  2,570\n",
      "==========================================================================================\n",
      "Total params: 2,797,610\n",
      "Trainable params: 2,797,610\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 146.15\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.25\n",
      "Params size (MB): 10.67\n",
      "Estimated Total Size (MB): 14.93\n",
      "==========================================================================================\n",
      "\n",
      "Epoch: 0\n",
      "Training epoch 0: Loss=1.590 Acc=41.254\n",
      "Testing epoch 0: Loss=1.387 Acc=50.060\n",
      "Saving..\n",
      "Epoch 0: 32.25s\n",
      "Train: 29.48s, Test: 2.77s\n",
      "\n",
      "Epoch: 1\n",
      "Training epoch 1: Loss=1.212 Acc=56.410\n",
      "Testing epoch 1: Loss=1.095 Acc=61.310\n",
      "Saving..\n",
      "Epoch 1: 64.20s\n",
      "Train: 29.25s, Test: 2.70s\n",
      "\n",
      "Epoch: 2\n",
      "Training epoch 2: Loss=1.018 Acc=64.070\n",
      "Testing epoch 2: Loss=0.964 Acc=66.150\n",
      "Saving..\n",
      "Epoch 2: 96.25s\n",
      "Train: 29.30s, Test: 2.75s\n",
      "\n",
      "Epoch: 3\n",
      "Training epoch 3: Loss=0.891 Acc=68.712\n",
      "Testing epoch 3: Loss=0.818 Acc=71.320\n",
      "Saving..\n",
      "Epoch 3: 128.60s\n",
      "Train: 29.54s, Test: 2.82s\n",
      "\n",
      "Epoch: 4\n",
      "Training epoch 4: Loss=0.792 Acc=72.166\n",
      "Testing epoch 4: Loss=0.793 Acc=72.270\n",
      "Saving..\n",
      "Epoch 4: 160.60s\n",
      "Train: 29.27s, Test: 2.72s\n",
      "\n",
      "Epoch: 5\n",
      "Training epoch 5: Loss=0.722 Acc=74.778\n",
      "Testing epoch 5: Loss=0.732 Acc=74.710\n",
      "Saving..\n",
      "Epoch 5: 192.85s\n",
      "Train: 29.53s, Test: 2.73s\n",
      "\n",
      "Epoch: 6\n",
      "Training epoch 6: Loss=0.660 Acc=77.102\n",
      "Testing epoch 6: Loss=0.679 Acc=76.410\n",
      "Saving..\n",
      "Epoch 6: 224.95s\n",
      "Train: 29.39s, Test: 2.71s\n",
      "\n",
      "Epoch: 7\n",
      "Training epoch 7: Loss=0.617 Acc=78.434\n",
      "Testing epoch 7: Loss=0.654 Acc=77.420\n",
      "Saving..\n",
      "Epoch 7: 256.56s\n",
      "Train: 29.13s, Test: 2.49s\n",
      "\n",
      "Epoch: 8\n",
      "Training epoch 8: Loss=0.574 Acc=80.002\n",
      "Testing epoch 8: Loss=0.615 Acc=79.420\n",
      "Saving..\n",
      "Epoch 8: 288.96s\n",
      "Train: 29.82s, Test: 2.58s\n",
      "\n",
      "Epoch: 9\n",
      "Training epoch 9: Loss=0.540 Acc=81.294\n",
      "Testing epoch 9: Loss=0.585 Acc=80.030\n",
      "Saving..\n",
      "Epoch 9: 321.26s\n",
      "Train: 29.72s, Test: 2.58s\n",
      "\n",
      "Epoch: 10\n",
      "Training epoch 10: Loss=0.508 Acc=82.410\n",
      "Testing epoch 10: Loss=0.567 Acc=81.020\n",
      "Saving..\n",
      "Epoch 10: 353.49s\n",
      "Train: 29.69s, Test: 2.54s\n",
      "\n",
      "Epoch: 11\n",
      "Training epoch 11: Loss=0.484 Acc=83.278\n",
      "Testing epoch 11: Loss=0.547 Acc=81.410\n",
      "Saving..\n",
      "Epoch 11: 386.31s\n",
      "Train: 30.13s, Test: 2.69s\n",
      "\n",
      "Epoch: 12\n",
      "Training epoch 12: Loss=0.455 Acc=84.294\n",
      "Testing epoch 12: Loss=0.531 Acc=81.570\n",
      "Saving..\n",
      "Epoch 12: 418.90s\n",
      "Train: 29.92s, Test: 2.67s\n",
      "\n",
      "Epoch: 13\n",
      "Training epoch 13: Loss=0.430 Acc=85.010\n",
      "Testing epoch 13: Loss=0.507 Acc=82.790\n",
      "Saving..\n",
      "Epoch 13: 451.37s\n",
      "Train: 29.95s, Test: 2.52s\n",
      "\n",
      "Epoch: 14\n",
      "Training epoch 14: Loss=0.418 Acc=85.502\n",
      "Testing epoch 14: Loss=0.532 Acc=82.030\n",
      "Epoch 14: 483.60s\n",
      "Train: 29.79s, Test: 2.44s\n",
      "\n",
      "Epoch: 15\n",
      "Training epoch 15: Loss=0.399 Acc=86.128\n",
      "Testing epoch 15: Loss=0.485 Acc=83.410\n",
      "Saving..\n",
      "Epoch 15: 516.20s\n",
      "Train: 30.14s, Test: 2.46s\n",
      "\n",
      "Epoch: 16\n",
      "Training epoch 16: Loss=0.378 Acc=86.904\n",
      "Testing epoch 16: Loss=0.461 Acc=84.200\n",
      "Saving..\n",
      "Epoch 16: 548.74s\n",
      "Train: 30.03s, Test: 2.51s\n",
      "\n",
      "Epoch: 17\n",
      "Training epoch 17: Loss=0.364 Acc=87.440\n",
      "Testing epoch 17: Loss=0.465 Acc=84.390\n",
      "Saving..\n",
      "Epoch 17: 581.32s\n",
      "Train: 30.20s, Test: 2.38s\n",
      "\n",
      "Epoch: 18\n",
      "Training epoch 18: Loss=0.349 Acc=87.958\n",
      "Testing epoch 18: Loss=0.464 Acc=84.390\n",
      "Epoch 18: 614.00s\n",
      "Train: 30.21s, Test: 2.47s\n",
      "\n",
      "Epoch: 19\n",
      "Training epoch 19: Loss=0.334 Acc=88.304\n",
      "Testing epoch 19: Loss=0.456 Acc=84.890\n",
      "Saving..\n",
      "Epoch 19: 646.50s\n",
      "Train: 30.16s, Test: 2.34s\n",
      "\n",
      "Epoch: 20\n",
      "Training epoch 20: Loss=0.321 Acc=88.846\n",
      "Testing epoch 20: Loss=0.464 Acc=84.890\n",
      "Epoch 20: 678.52s\n",
      "Train: 29.73s, Test: 2.29s\n",
      "\n",
      "Epoch: 21\n",
      "Training epoch 21: Loss=0.307 Acc=89.222\n",
      "Testing epoch 21: Loss=0.435 Acc=86.010\n",
      "Saving..\n",
      "Epoch 21: 710.69s\n",
      "Train: 29.71s, Test: 2.46s\n",
      "\n",
      "Epoch: 22\n",
      "Training epoch 22: Loss=0.297 Acc=89.668\n",
      "Testing epoch 22: Loss=0.435 Acc=85.700\n",
      "Epoch 22: 743.14s\n",
      "Train: 29.76s, Test: 2.68s\n",
      "\n",
      "Epoch: 23\n",
      "Training epoch 23: Loss=0.287 Acc=89.858\n",
      "Testing epoch 23: Loss=0.447 Acc=85.580\n",
      "Epoch 23: 775.24s\n",
      "Train: 29.57s, Test: 2.53s\n",
      "\n",
      "Epoch: 24\n",
      "Training epoch 24: Loss=0.274 Acc=90.430\n",
      "Testing epoch 24: Loss=0.538 Acc=82.680\n",
      "Epoch 24: 807.46s\n",
      "Train: 29.72s, Test: 2.50s\n",
      "\n",
      "Epoch: 25\n",
      "Training epoch 25: Loss=0.263 Acc=90.760\n",
      "Testing epoch 25: Loss=0.441 Acc=86.220\n",
      "Saving..\n",
      "Epoch 25: 839.66s\n",
      "Train: 29.61s, Test: 2.60s\n",
      "\n",
      "Epoch: 26\n",
      "Training epoch 26: Loss=0.252 Acc=91.162\n",
      "Testing epoch 26: Loss=0.431 Acc=86.520\n",
      "Saving..\n",
      "Epoch 26: 871.71s\n",
      "Train: 29.20s, Test: 2.84s\n",
      "\n",
      "Epoch: 27\n",
      "Training epoch 27: Loss=0.245 Acc=91.510\n",
      "Testing epoch 27: Loss=0.412 Acc=86.840\n",
      "Saving..\n",
      "Epoch 27: 903.61s\n",
      "Train: 29.19s, Test: 2.71s\n",
      "\n",
      "Epoch: 28\n",
      "Training epoch 28: Loss=0.233 Acc=91.790\n",
      "Testing epoch 28: Loss=0.439 Acc=86.560\n",
      "Epoch 28: 935.57s\n",
      "Train: 29.22s, Test: 2.74s\n",
      "\n",
      "Epoch: 29\n",
      "Training epoch 29: Loss=0.229 Acc=91.968\n",
      "Testing epoch 29: Loss=0.411 Acc=87.090\n",
      "Saving..\n",
      "Epoch 29: 967.43s\n",
      "Train: 29.08s, Test: 2.78s\n",
      "\n",
      "Epoch: 30\n",
      "Training epoch 30: Loss=0.222 Acc=92.248\n",
      "Testing epoch 30: Loss=0.433 Acc=86.740\n",
      "Epoch 30: 999.23s\n",
      "Train: 29.00s, Test: 2.80s\n",
      "\n",
      "Epoch: 31\n",
      "Training epoch 31: Loss=0.211 Acc=92.650\n",
      "Testing epoch 31: Loss=0.424 Acc=86.710\n",
      "Epoch 31: 1030.92s\n",
      "Train: 28.91s, Test: 2.78s\n",
      "\n",
      "Epoch: 32\n",
      "Training epoch 32: Loss=0.204 Acc=92.844\n",
      "Testing epoch 32: Loss=0.428 Acc=86.560\n",
      "Epoch 32: 1062.57s\n",
      "Train: 28.87s, Test: 2.78s\n",
      "\n",
      "Epoch: 33\n",
      "Training epoch 33: Loss=0.192 Acc=93.316\n",
      "Testing epoch 33: Loss=0.447 Acc=86.650\n",
      "Epoch 33: 1094.28s\n",
      "Train: 29.09s, Test: 2.61s\n",
      "\n",
      "Epoch: 34\n",
      "Training epoch 34: Loss=0.190 Acc=93.336\n",
      "Testing epoch 34: Loss=0.429 Acc=86.930\n",
      "Epoch 34: 1125.42s\n",
      "Train: 28.46s, Test: 2.67s\n",
      "\n",
      "Epoch: 35\n",
      "Training epoch 35: Loss=0.187 Acc=93.328\n",
      "Testing epoch 35: Loss=0.418 Acc=87.100\n",
      "Saving..\n",
      "Epoch 35: 1157.08s\n",
      "Train: 28.82s, Test: 2.84s\n",
      "\n",
      "Epoch: 36\n",
      "Training epoch 36: Loss=0.176 Acc=93.840\n",
      "Testing epoch 36: Loss=0.450 Acc=86.390\n",
      "Epoch 36: 1188.54s\n",
      "Train: 28.76s, Test: 2.71s\n",
      "\n",
      "Epoch: 37\n",
      "Training epoch 37: Loss=0.170 Acc=94.004\n",
      "Testing epoch 37: Loss=0.418 Acc=87.460\n",
      "Saving..\n",
      "Epoch 37: 1220.52s\n",
      "Train: 29.08s, Test: 2.90s\n",
      "\n",
      "Epoch: 38\n",
      "Training epoch 38: Loss=0.162 Acc=94.184\n",
      "Testing epoch 38: Loss=0.480 Acc=86.320\n",
      "Epoch 38: 1252.23s\n",
      "Train: 28.99s, Test: 2.72s\n",
      "\n",
      "Epoch: 39\n",
      "Training epoch 39: Loss=0.160 Acc=94.342\n",
      "Testing epoch 39: Loss=0.453 Acc=87.220\n",
      "Epoch 39: 1283.89s\n",
      "Train: 29.07s, Test: 2.60s\n",
      "\n",
      "Epoch: 40\n",
      "Training epoch 40: Loss=0.154 Acc=94.578\n",
      "Testing epoch 40: Loss=0.479 Acc=86.380\n",
      "Epoch 40: 1315.37s\n",
      "Train: 28.80s, Test: 2.67s\n",
      "\n",
      "Epoch: 41\n",
      "Training epoch 41: Loss=0.150 Acc=94.798\n",
      "Testing epoch 41: Loss=0.453 Acc=87.350\n",
      "Epoch 41: 1347.08s\n",
      "Train: 28.98s, Test: 2.73s\n",
      "\n",
      "Epoch: 42\n",
      "Training epoch 42: Loss=0.148 Acc=94.734\n",
      "Testing epoch 42: Loss=0.466 Acc=87.090\n",
      "Epoch 42: 1379.13s\n",
      "Train: 29.22s, Test: 2.83s\n",
      "\n",
      "Epoch: 43\n",
      "Training epoch 43: Loss=0.147 Acc=94.756\n",
      "Testing epoch 43: Loss=0.450 Acc=87.510\n",
      "Saving..\n",
      "Epoch 43: 1410.97s\n",
      "Train: 28.98s, Test: 2.86s\n",
      "\n",
      "Epoch: 44\n",
      "Training epoch 44: Loss=0.134 Acc=95.242\n",
      "Testing epoch 44: Loss=0.471 Acc=87.030\n",
      "Epoch 44: 1442.54s\n",
      "Train: 28.97s, Test: 2.60s\n",
      "\n",
      "Epoch: 45\n",
      "Training epoch 45: Loss=0.133 Acc=95.300\n",
      "Testing epoch 45: Loss=0.436 Acc=87.380\n",
      "Epoch 45: 1474.16s\n",
      "Train: 29.01s, Test: 2.61s\n",
      "\n",
      "Epoch: 46\n",
      "Training epoch 46: Loss=0.125 Acc=95.672\n",
      "Testing epoch 46: Loss=0.436 Acc=87.930\n",
      "Saving..\n",
      "Epoch 46: 1506.16s\n",
      "Train: 29.16s, Test: 2.84s\n",
      "\n",
      "Epoch: 47\n",
      "Training epoch 47: Loss=0.124 Acc=95.628\n",
      "Testing epoch 47: Loss=0.472 Acc=87.520\n",
      "Epoch 47: 1537.87s\n",
      "Train: 28.97s, Test: 2.74s\n",
      "\n",
      "Epoch: 48\n",
      "Training epoch 48: Loss=0.121 Acc=95.678\n",
      "Testing epoch 48: Loss=0.439 Acc=88.020\n",
      "Saving..\n",
      "Epoch 48: 1569.44s\n",
      "Train: 28.84s, Test: 2.73s\n",
      "\n",
      "Epoch: 49\n",
      "Training epoch 49: Loss=0.120 Acc=95.800\n",
      "Testing epoch 49: Loss=0.466 Acc=87.610\n",
      "Epoch 49: 1601.20s\n",
      "Train: 28.96s, Test: 2.81s\n",
      "\n",
      "Epoch: 50\n",
      "Training epoch 50: Loss=0.110 Acc=96.140\n",
      "Testing epoch 50: Loss=0.496 Acc=86.920\n",
      "Epoch 50: 1632.58s\n",
      "Train: 28.79s, Test: 2.59s\n",
      "\n",
      "Epoch: 51\n",
      "Training epoch 51: Loss=0.108 Acc=96.118\n",
      "Testing epoch 51: Loss=0.466 Acc=87.640\n",
      "Epoch 51: 1664.21s\n",
      "Train: 28.68s, Test: 2.95s\n",
      "\n",
      "Epoch: 52\n",
      "Training epoch 52: Loss=0.106 Acc=96.248\n",
      "Testing epoch 52: Loss=0.447 Acc=88.560\n",
      "Saving..\n",
      "Epoch 52: 1696.20s\n",
      "Train: 29.05s, Test: 2.94s\n",
      "\n",
      "Epoch: 53\n",
      "Training epoch 53: Loss=0.104 Acc=96.242\n",
      "Testing epoch 53: Loss=0.462 Acc=87.640\n",
      "Epoch 53: 1727.84s\n",
      "Train: 28.96s, Test: 2.68s\n",
      "\n",
      "Epoch: 54\n",
      "Training epoch 54: Loss=0.105 Acc=96.234\n",
      "Testing epoch 54: Loss=0.440 Acc=88.430\n",
      "Epoch 54: 1759.50s\n",
      "Train: 29.00s, Test: 2.67s\n",
      "\n",
      "Epoch: 55\n",
      "Training epoch 55: Loss=0.099 Acc=96.478\n",
      "Testing epoch 55: Loss=0.451 Acc=88.270\n",
      "Epoch 55: 1790.90s\n",
      "Train: 28.82s, Test: 2.58s\n",
      "\n",
      "Epoch: 56\n",
      "Training epoch 56: Loss=0.096 Acc=96.520\n",
      "Testing epoch 56: Loss=0.475 Acc=87.590\n",
      "Epoch 56: 1822.38s\n",
      "Train: 28.76s, Test: 2.72s\n",
      "\n",
      "Epoch: 57\n",
      "Training epoch 57: Loss=0.098 Acc=96.492\n",
      "Testing epoch 57: Loss=0.464 Acc=87.940\n",
      "Epoch 57: 1853.94s\n",
      "Train: 28.85s, Test: 2.71s\n",
      "\n",
      "Epoch: 58\n",
      "Training epoch 58: Loss=0.091 Acc=96.764\n",
      "Testing epoch 58: Loss=0.450 Acc=88.550\n",
      "Epoch 58: 1885.57s\n",
      "Train: 28.95s, Test: 2.68s\n",
      "\n",
      "Epoch: 59\n",
      "Training epoch 59: Loss=0.090 Acc=96.780\n",
      "Testing epoch 59: Loss=0.467 Acc=88.240\n",
      "Epoch 59: 1916.97s\n",
      "Train: 28.68s, Test: 2.72s\n",
      "\n",
      "Epoch: 60\n",
      "Training epoch 60: Loss=0.092 Acc=96.748\n",
      "Testing epoch 60: Loss=0.473 Acc=88.290\n",
      "Epoch 60: 1948.68s\n",
      "Train: 28.97s, Test: 2.75s\n",
      "\n",
      "Epoch: 61\n",
      "Training epoch 61: Loss=0.085 Acc=96.982\n",
      "Testing epoch 61: Loss=0.442 Acc=88.850\n",
      "Saving..\n",
      "Epoch 61: 1980.64s\n",
      "Train: 29.32s, Test: 2.64s\n",
      "\n",
      "Epoch: 62\n",
      "Training epoch 62: Loss=0.080 Acc=97.116\n",
      "Testing epoch 62: Loss=0.491 Acc=88.020\n",
      "Epoch 62: 2012.18s\n",
      "Train: 28.72s, Test: 2.82s\n",
      "\n",
      "Epoch: 63\n",
      "Training epoch 63: Loss=0.081 Acc=97.100\n",
      "Testing epoch 63: Loss=0.480 Acc=88.410\n",
      "Epoch 63: 2043.93s\n",
      "Train: 29.09s, Test: 2.66s\n",
      "\n",
      "Epoch: 64\n",
      "Training epoch 64: Loss=0.083 Acc=96.990\n",
      "Testing epoch 64: Loss=0.499 Acc=88.130\n",
      "Epoch 64: 2075.44s\n",
      "Train: 28.96s, Test: 2.56s\n",
      "\n",
      "Epoch: 65\n",
      "Training epoch 65: Loss=0.079 Acc=97.220\n",
      "Testing epoch 65: Loss=0.493 Acc=88.120\n",
      "Epoch 65: 2107.33s\n",
      "Train: 29.13s, Test: 2.76s\n",
      "\n",
      "Epoch: 66\n",
      "Training epoch 66: Loss=0.077 Acc=97.296\n",
      "Testing epoch 66: Loss=0.530 Acc=88.100\n",
      "Epoch 66: 2138.95s\n",
      "Train: 29.06s, Test: 2.57s\n",
      "\n",
      "Epoch: 67\n",
      "Training epoch 67: Loss=0.075 Acc=97.416\n",
      "Testing epoch 67: Loss=0.487 Acc=88.320\n",
      "Epoch 67: 2170.49s\n",
      "Train: 29.00s, Test: 2.53s\n",
      "\n",
      "Epoch: 68\n",
      "Training epoch 68: Loss=0.076 Acc=97.336\n",
      "Testing epoch 68: Loss=0.511 Acc=88.520\n",
      "Epoch 68: 2202.16s\n",
      "Train: 29.10s, Test: 2.57s\n",
      "\n",
      "Epoch: 69\n",
      "Training epoch 69: Loss=0.074 Acc=97.410\n",
      "Testing epoch 69: Loss=0.511 Acc=88.070\n",
      "Epoch 69: 2233.94s\n",
      "Train: 29.23s, Test: 2.55s\n",
      "\n",
      "Epoch: 70\n",
      "Training epoch 70: Loss=0.071 Acc=97.508\n",
      "Testing epoch 70: Loss=0.476 Acc=88.740\n",
      "Epoch 70: 2265.65s\n",
      "Train: 29.06s, Test: 2.64s\n",
      "\n",
      "Epoch: 71\n",
      "Training epoch 71: Loss=0.066 Acc=97.634\n",
      "Testing epoch 71: Loss=0.469 Acc=89.180\n",
      "Saving..\n",
      "Epoch 71: 2297.29s\n",
      "Train: 29.06s, Test: 2.58s\n",
      "\n",
      "Epoch: 72\n",
      "Training epoch 72: Loss=0.064 Acc=97.782\n",
      "Testing epoch 72: Loss=0.494 Acc=88.650\n",
      "Epoch 72: 2328.90s\n",
      "Train: 28.98s, Test: 2.63s\n",
      "\n",
      "Epoch: 73\n",
      "Training epoch 73: Loss=0.067 Acc=97.652\n",
      "Testing epoch 73: Loss=0.484 Acc=88.840\n",
      "Epoch 73: 2361.04s\n",
      "Train: 29.47s, Test: 2.67s\n",
      "\n",
      "Epoch: 74\n",
      "Training epoch 74: Loss=0.064 Acc=97.790\n",
      "Testing epoch 74: Loss=0.497 Acc=88.920\n",
      "Epoch 74: 2392.42s\n",
      "Train: 28.91s, Test: 2.46s\n",
      "\n",
      "Epoch: 75\n",
      "Training epoch 75: Loss=0.063 Acc=97.760\n",
      "Testing epoch 75: Loss=0.556 Acc=87.610\n",
      "Epoch 75: 2424.03s\n",
      "Train: 28.93s, Test: 2.68s\n",
      "\n",
      "Epoch: 76\n",
      "Training epoch 76: Loss=0.063 Acc=97.760\n",
      "Testing epoch 76: Loss=0.504 Acc=88.830\n",
      "Epoch 76: 2455.48s\n",
      "Train: 28.91s, Test: 2.54s\n",
      "\n",
      "Epoch: 77\n",
      "Training epoch 77: Loss=0.062 Acc=97.762\n",
      "Testing epoch 77: Loss=0.511 Acc=88.650\n",
      "Epoch 77: 2487.29s\n",
      "Train: 29.22s, Test: 2.59s\n",
      "\n",
      "Epoch: 78\n",
      "Training epoch 78: Loss=0.059 Acc=97.944\n",
      "Testing epoch 78: Loss=0.486 Acc=88.780\n",
      "Epoch 78: 2518.91s\n",
      "Train: 29.03s, Test: 2.59s\n",
      "\n",
      "Epoch: 79\n",
      "Training epoch 79: Loss=0.059 Acc=97.910\n",
      "Testing epoch 79: Loss=0.499 Acc=88.820\n",
      "Epoch 79: 2550.66s\n",
      "Train: 29.13s, Test: 2.62s\n",
      "\n",
      "Epoch: 80\n",
      "Training epoch 80: Loss=0.060 Acc=97.882\n",
      "Testing epoch 80: Loss=0.519 Acc=88.220\n",
      "Epoch 80: 2582.40s\n",
      "Train: 29.11s, Test: 2.63s\n",
      "\n",
      "Epoch: 81\n",
      "Training epoch 81: Loss=0.056 Acc=97.992\n",
      "Testing epoch 81: Loss=0.517 Acc=88.640\n",
      "Epoch 81: 2614.16s\n",
      "Train: 29.18s, Test: 2.58s\n",
      "\n",
      "Epoch: 82\n",
      "Training epoch 82: Loss=0.056 Acc=98.048\n",
      "Testing epoch 82: Loss=0.532 Acc=88.740\n",
      "Epoch 82: 2646.14s\n",
      "Train: 29.44s, Test: 2.55s\n",
      "\n",
      "Epoch: 83\n",
      "Training epoch 83: Loss=0.058 Acc=97.986\n",
      "Testing epoch 83: Loss=0.480 Acc=89.220\n",
      "Saving..\n",
      "Epoch 83: 2678.12s\n",
      "Train: 29.45s, Test: 2.52s\n",
      "\n",
      "Epoch: 84\n",
      "Training epoch 84: Loss=0.052 Acc=98.206\n",
      "Testing epoch 84: Loss=0.507 Acc=88.870\n",
      "Epoch 84: 2710.04s\n",
      "Train: 29.45s, Test: 2.47s\n",
      "\n",
      "Epoch: 85\n",
      "Training epoch 85: Loss=0.053 Acc=98.120\n",
      "Testing epoch 85: Loss=0.510 Acc=88.850\n",
      "Epoch 85: 2742.21s\n",
      "Train: 29.62s, Test: 2.54s\n",
      "\n",
      "Epoch: 86\n",
      "Training epoch 86: Loss=0.055 Acc=98.078\n",
      "Testing epoch 86: Loss=0.503 Acc=89.000\n",
      "Epoch 86: 2774.57s\n",
      "Train: 29.65s, Test: 2.71s\n",
      "\n",
      "Epoch: 87\n",
      "Training epoch 87: Loss=0.054 Acc=98.142\n",
      "Testing epoch 87: Loss=0.512 Acc=88.850\n",
      "Epoch 87: 2806.80s\n",
      "Train: 29.66s, Test: 2.57s\n",
      "\n",
      "Epoch: 88\n",
      "Training epoch 88: Loss=0.049 Acc=98.254\n",
      "Testing epoch 88: Loss=0.517 Acc=88.930\n",
      "Epoch 88: 2839.15s\n",
      "Train: 29.70s, Test: 2.64s\n",
      "\n",
      "Epoch: 89\n",
      "Training epoch 89: Loss=0.051 Acc=98.172\n",
      "Testing epoch 89: Loss=0.507 Acc=89.510\n",
      "Saving..\n",
      "Epoch 89: 2871.69s\n",
      "Train: 30.01s, Test: 2.54s\n",
      "\n",
      "Epoch: 90\n",
      "Training epoch 90: Loss=0.051 Acc=98.226\n",
      "Testing epoch 90: Loss=0.501 Acc=89.150\n",
      "Epoch 90: 2904.01s\n",
      "Train: 29.94s, Test: 2.38s\n",
      "\n",
      "Epoch: 91\n",
      "Training epoch 91: Loss=0.053 Acc=98.152\n",
      "Testing epoch 91: Loss=0.541 Acc=88.760\n",
      "Epoch 91: 2937.09s\n",
      "Train: 30.52s, Test: 2.56s\n",
      "\n",
      "Epoch: 92\n",
      "Training epoch 92: Loss=0.045 Acc=98.376\n",
      "Testing epoch 92: Loss=0.527 Acc=89.050\n",
      "Epoch 92: 2969.43s\n",
      "Train: 29.86s, Test: 2.48s\n",
      "\n",
      "Epoch: 93\n",
      "Training epoch 93: Loss=0.046 Acc=98.360\n",
      "Testing epoch 93: Loss=0.519 Acc=89.060\n",
      "Epoch 93: 3001.60s\n",
      "Train: 29.67s, Test: 2.49s\n",
      "\n",
      "Epoch: 94\n",
      "Training epoch 94: Loss=0.046 Acc=98.392\n",
      "Testing epoch 94: Loss=0.517 Acc=89.140\n",
      "Epoch 94: 3033.29s\n",
      "Train: 29.14s, Test: 2.55s\n",
      "\n",
      "Epoch: 95\n",
      "Training epoch 95: Loss=0.048 Acc=98.402\n",
      "Testing epoch 95: Loss=0.521 Acc=88.880\n",
      "Epoch 95: 3065.11s\n",
      "Train: 29.17s, Test: 2.66s\n",
      "\n",
      "Epoch: 96\n",
      "Training epoch 96: Loss=0.046 Acc=98.380\n",
      "Testing epoch 96: Loss=0.559 Acc=88.350\n",
      "Epoch 96: 3096.85s\n",
      "Train: 29.11s, Test: 2.62s\n",
      "\n",
      "Epoch: 97\n",
      "Training epoch 97: Loss=0.044 Acc=98.488\n",
      "Testing epoch 97: Loss=0.526 Acc=88.880\n",
      "Epoch 97: 3128.45s\n",
      "Train: 28.97s, Test: 2.63s\n",
      "\n",
      "Epoch: 98\n",
      "Training epoch 98: Loss=0.042 Acc=98.494\n",
      "Testing epoch 98: Loss=0.557 Acc=88.860\n",
      "Epoch 98: 3160.39s\n",
      "Train: 29.24s, Test: 2.70s\n",
      "\n",
      "Epoch: 99\n",
      "Training epoch 99: Loss=0.043 Acc=98.502\n",
      "Testing epoch 99: Loss=0.513 Acc=89.450\n",
      "Epoch 99: 3192.13s\n",
      "Train: 29.02s, Test: 2.72s\n",
      "\n",
      "Epoch: 100\n",
      "Training epoch 100: Loss=0.043 Acc=98.484\n",
      "Testing epoch 100: Loss=0.514 Acc=89.390\n",
      "Epoch 100: 3223.88s\n",
      "Train: 28.95s, Test: 2.80s\n",
      "\n",
      "Epoch: 101\n",
      "Training epoch 101: Loss=0.048 Acc=98.354\n",
      "Testing epoch 101: Loss=0.544 Acc=89.070\n",
      "Epoch 101: 3255.48s\n",
      "Train: 28.93s, Test: 2.68s\n",
      "\n",
      "Epoch: 102\n",
      "Training epoch 102: Loss=0.045 Acc=98.402\n",
      "Testing epoch 102: Loss=0.521 Acc=89.050\n",
      "Epoch 102: 3287.16s\n",
      "Train: 28.93s, Test: 2.75s\n",
      "\n",
      "Epoch: 103\n",
      "Training epoch 103: Loss=0.040 Acc=98.642\n",
      "Testing epoch 103: Loss=0.501 Acc=89.600\n",
      "Saving..\n",
      "Epoch 103: 3319.25s\n",
      "Train: 29.31s, Test: 2.78s\n",
      "\n",
      "Epoch: 104\n",
      "Training epoch 104: Loss=0.041 Acc=98.542\n",
      "Testing epoch 104: Loss=0.540 Acc=89.030\n",
      "Epoch 104: 3351.11s\n",
      "Train: 29.08s, Test: 2.79s\n",
      "\n",
      "Epoch: 105\n",
      "Training epoch 105: Loss=0.038 Acc=98.690\n",
      "Testing epoch 105: Loss=0.559 Acc=88.530\n",
      "Epoch 105: 3382.99s\n",
      "Train: 29.29s, Test: 2.58s\n",
      "\n",
      "Epoch: 106\n",
      "Training epoch 106: Loss=0.043 Acc=98.468\n",
      "Testing epoch 106: Loss=0.590 Acc=88.150\n",
      "Epoch 106: 3414.70s\n",
      "Train: 28.94s, Test: 2.77s\n",
      "\n",
      "Epoch: 107\n",
      "Training epoch 107: Loss=0.041 Acc=98.548\n",
      "Testing epoch 107: Loss=0.519 Acc=89.590\n",
      "Epoch 107: 3446.35s\n",
      "Train: 28.88s, Test: 2.77s\n",
      "\n",
      "Epoch: 108\n",
      "Training epoch 108: Loss=0.041 Acc=98.574\n",
      "Testing epoch 108: Loss=0.529 Acc=89.410\n",
      "Epoch 108: 3477.97s\n",
      "Train: 28.85s, Test: 2.76s\n",
      "\n",
      "Epoch: 109\n",
      "Training epoch 109: Loss=0.040 Acc=98.610\n",
      "Testing epoch 109: Loss=0.555 Acc=88.870\n",
      "Epoch 109: 3509.55s\n",
      "Train: 28.74s, Test: 2.84s\n",
      "\n",
      "Epoch: 110\n",
      "Training epoch 110: Loss=0.035 Acc=98.764\n",
      "Testing epoch 110: Loss=0.554 Acc=88.700\n",
      "Epoch 110: 3541.54s\n",
      "Train: 29.24s, Test: 2.75s\n",
      "\n",
      "Epoch: 111\n",
      "Training epoch 111: Loss=0.037 Acc=98.704\n",
      "Testing epoch 111: Loss=0.541 Acc=88.840\n",
      "Epoch 111: 3573.55s\n",
      "Train: 29.16s, Test: 2.85s\n",
      "\n",
      "Epoch: 112\n",
      "Training epoch 112: Loss=0.038 Acc=98.668\n",
      "Testing epoch 112: Loss=0.539 Acc=88.940\n",
      "Epoch 112: 3605.41s\n",
      "Train: 29.07s, Test: 2.80s\n",
      "\n",
      "Epoch: 113\n",
      "Training epoch 113: Loss=0.037 Acc=98.686\n",
      "Testing epoch 113: Loss=0.562 Acc=89.010\n",
      "Epoch 113: 3637.07s\n",
      "Train: 28.88s, Test: 2.78s\n",
      "\n",
      "Epoch: 114\n",
      "Training epoch 114: Loss=0.040 Acc=98.610\n",
      "Testing epoch 114: Loss=0.561 Acc=89.060\n",
      "Epoch 114: 3669.03s\n",
      "Train: 29.09s, Test: 2.87s\n",
      "\n",
      "Epoch: 115\n",
      "Training epoch 115: Loss=0.034 Acc=98.830\n",
      "Testing epoch 115: Loss=0.554 Acc=89.190\n",
      "Epoch 115: 3700.99s\n",
      "Train: 29.14s, Test: 2.83s\n",
      "\n",
      "Epoch: 116\n",
      "Training epoch 116: Loss=0.034 Acc=98.818\n",
      "Testing epoch 116: Loss=0.542 Acc=89.580\n",
      "Epoch 116: 3732.99s\n",
      "Train: 29.09s, Test: 2.90s\n",
      "\n",
      "Epoch: 117\n",
      "Training epoch 117: Loss=0.038 Acc=98.682\n",
      "Testing epoch 117: Loss=0.507 Acc=89.700\n",
      "Saving..\n",
      "Epoch 117: 3765.21s\n",
      "Train: 29.27s, Test: 2.95s\n",
      "\n",
      "Epoch: 118\n",
      "Training epoch 118: Loss=0.038 Acc=98.654\n",
      "Testing epoch 118: Loss=0.547 Acc=89.170\n",
      "Epoch 118: 3797.31s\n",
      "Train: 29.19s, Test: 2.91s\n",
      "\n",
      "Epoch: 119\n",
      "Training epoch 119: Loss=0.035 Acc=98.776\n",
      "Testing epoch 119: Loss=0.571 Acc=89.020\n",
      "Epoch 119: 3829.20s\n",
      "Train: 28.97s, Test: 2.92s\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "# parser.add_argument('--resume', '-r', action='store_true',\n",
    "#                     help='resume from checkpoint')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "Learning_rate = 0.0001\n",
    "Resume = False\n",
    "Optimizer = 'adam'  # sgd, sgdn, adagrad, adadelta or adam\n",
    "Batch_size = 128\n",
    "\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=Batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if Resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.SGD(net.parameters(), lr=Learning_rate,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "if Optimizer == 'sgdn':\n",
    "    optimizer = optim.SGD(net.parameters(), lr=Learning_rate,\n",
    "                    momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "elif Optimizer == 'adagrad':\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=Learning_rate,\n",
    "                              weight_decay=5e-4)\n",
    "elif Optimizer == 'adadelta':\n",
    "    optimizer = optim.Adadelta(net.parameters(), lr=Learning_rate,\n",
    "                               weight_decay=5e-4)\n",
    "elif Optimizer == 'adam':\n",
    "    optimizer = optim.Adam(net.parameters(), lr=Learning_rate,\n",
    "                           weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "torchsummary.summary(net, (3, 32, 32))\n",
    "\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_training_time = 0\n",
    "    time1 = torch.cuda.Event(enable_timing=True)\n",
    "    time2 = torch.cuda.Event(enable_timing=True)\n",
    "    time1.record()\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        time2.record()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        total_training_time += time1.elapsed_time(time2)\n",
    "        \n",
    "    avg_loss = train_loss/total\n",
    "    acc = 100.*correct/total\n",
    "    print('Training epoch %d: Loss=%.3f Acc=%.3f' %\n",
    "          (epoch, avg_loss, acc))\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    avg_loss = test_loss/total\n",
    "    acc = 100.*correct/total\n",
    "    print('Testing epoch %d: Loss=%.3f Acc=%.3f' %\n",
    "          (epoch, avg_loss, acc))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "filename = Optimizer + '_' + str(Batch_size) + '_' + str(Learning_rate) + '_dropout.csv'\n",
    "file = open(filename, 'w')\n",
    "file.write('train_avg_loss, train_acc, test_avg_loss, test_acc, train_time, test_time\\n')\n",
    "Start_time = time.perf_counter()\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "for epoch in range(start_epoch, start_epoch+120):\n",
    "    time1 = time.perf_counter()\n",
    "    train_avg_loss, train_acc = train(epoch)\n",
    "    time2 = time.perf_counter()\n",
    "    test_avg_loss, test_acc = test(epoch)\n",
    "    Cur_time = time.perf_counter()\n",
    "    # scheduler.step()\n",
    "    train_acc_history.append(train_acc)\n",
    "    test_acc_history.append(test_acc)\n",
    "    print('Epoch %d: %.2fs' % (epoch, Cur_time - Start_time))\n",
    "    print('Train: %.2fs, Test: %.2fs' % (time2 - time1, Cur_time - time2))\n",
    "    file.write('%.3f, %.3f, %.3f, %.3f, %.2f, %.2f\\n' %\n",
    "               (train_avg_loss, train_acc, test_avg_loss, test_acc,\n",
    "                time2 - time1, Cur_time - time2))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c68f0b31-f395-46c9-876c-a07fb748e04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f432c165a30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(120),train_acc_history,'-',linewidth=3,label='Train accuracy')\n",
    "plt.plot(range(120),test_acc_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59b11a-b2dc-4d9b-aea0-5e8e79e151f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
