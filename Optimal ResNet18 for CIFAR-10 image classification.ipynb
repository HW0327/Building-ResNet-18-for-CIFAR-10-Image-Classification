{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0ac129-4b37-4804-8613-3b639d238c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
      "  libsqlite          conda-forge/linux-64::libsqlite-3.40.0-h753d276_0\n",
      "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4\n",
      "  toolz              conda-forge/noarch::toolz-0.12.0-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  chardet-4.0.0-py39hf3d152e_1\n",
      "  libstdcxx-ng-11.2.0-he4da1e4_9\n",
      "  six-1.16.0-pyh6c4a22f_0\n",
      "  sqlite-3.36.0-h9cd32fc_2\n",
      "  zlib-1.2.11-h516909a_1010\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  _openmp_mutex                                   4.5-1_gnu --> 4.5-2_gnu\n",
      "  brotlipy                          0.7.0-py39h3811e60_1001 --> 0.7.0-py39hb9d737c_1005\n",
      "  ca-certificates                      2021.5.30-ha878542_0 --> 2022.9.24-ha878542_0\n",
      "  certifi            conda-forge/linux-64::certifi-2021.5.~ --> conda-forge/noarch::certifi-2022.9.24-pyhd8ed1ab_0\n",
      "  cffi                                1.14.6-py39h4bc2ebd_1 --> 1.15.1-py39he91dace_2\n",
      "  charset-normalizer                     2.0.0-pyhd8ed1ab_0 --> 2.1.1-pyhd8ed1ab_0\n",
      "  colorama                               0.4.4-pyh9f0ad1d_0 --> 0.4.6-pyhd8ed1ab_0\n",
      "  conda                               4.10.3-py39hf3d152e_2 --> 22.9.0-py39hf3d152e_2\n",
      "  conda-package-han~                   1.7.3-py39h3811e60_0 --> 1.9.0-py39hb9d737c_1\n",
      "  cryptography                         3.4.7-py39hbca0aa6_0 --> 38.0.3-py39h3ccb8fc_0\n",
      "  idna                                     3.1-pyhd3deb0d_0 --> 3.4-pyhd8ed1ab_0\n",
      "  ld_impl_linux-64                        2.36.1-hea4e1c9_2 --> 2.39-hcc3a1bd_1\n",
      "  libffi                                   3.4.2-h9c3ff4c_4 --> 3.4.2-h7f98852_5\n",
      "  libgcc-ng                               11.2.0-h1d223b6_9 --> 12.2.0-h65d4601_19\n",
      "  libgomp                                 11.2.0-h1d223b6_9 --> 12.2.0-h65d4601_19\n",
      "  ncurses                                    6.2-h58526e2_4 --> 6.3-h27087fc_1\n",
      "  openssl                                 1.1.1l-h7f98852_0 --> 3.0.7-h166bdaf_0\n",
      "  pycosat                           0.6.3-py39h3811e60_1006 --> 0.6.4-py39hb9d737c_1\n",
      "  pycparser                               2.20-pyh9f0ad1d_2 --> 2.21-pyhd8ed1ab_0\n",
      "  pyopenssl                             20.0.1-pyhd8ed1ab_0 --> 22.1.0-pyhd8ed1ab_0\n",
      "  pysocks            conda-forge/linux-64::pysocks-1.7.1-p~ --> conda-forge/noarch::pysocks-1.7.1-pyha2e5f31_6\n",
      "  python                           3.9.7-hb7a2778_2_cpython --> 3.9.14-hba424b6_0_cpython\n",
      "  python_abi                                     3.9-2_cp39 --> 3.9-3_cp39\n",
      "  readline                                   8.1-h46c0cb4_0 --> 8.1.2-h0f457ee_0\n",
      "  requests                              2.26.0-pyhd8ed1ab_0 --> 2.28.1-pyhd8ed1ab_1\n",
      "  ruamel_yaml                     0.15.80-py39h3811e60_1004 --> 0.15.80-py39hb9d737c_1008\n",
      "  setuptools         conda-forge/linux-64::setuptools-58.0~ --> conda-forge/noarch::setuptools-65.5.1-pyhd8ed1ab_0\n",
      "  tk                                      8.6.11-h27826a3_1 --> 8.6.12-h27826a3_0\n",
      "  tqdm                                  4.62.3-pyhd8ed1ab_0 --> 4.64.1-pyhd8ed1ab_0\n",
      "  tzdata                                   2021a-he74cb21_1 --> 2022f-h191b570_0\n",
      "  urllib3                               1.26.7-pyhd8ed1ab_0 --> 1.26.11-pyhd8ed1ab_0\n",
      "  wheel                                 0.37.0-pyhd8ed1ab_1 --> 0.38.4-pyhd8ed1ab_0\n",
      "  xz                                       5.2.5-h516909a_1 --> 5.2.6-h166bdaf_0\n",
      "  yaml                                     0.2.5-h516909a_0 --> 0.2.5-h7f98852_2\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /opt/conda\n",
      "  uid: 1000\n",
      "  gid: 100\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch-summary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda update -n base conda\n",
    "%conda install pytorch\n",
    "%conda install torchvision\n",
    "%pip install torch-summary\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe482f3-2fa2-47d3-ab9b-0e1616293a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchsummary\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551c0cf9-162e-42d1-a813-e58d4871c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "\n",
    "# _, term_width = os.popen('stty size', 'r').read().split()\n",
    "term_width = 50\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd8107b7-5d71-4168-88ad-ca44e8e1ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2688f85b-1fc7-48a0-b1f6-0373074e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb8fbf6-ee1d-4fd3-bfc1-62dd014c5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50d30e2-ae7f-44ed-a9ef-8b6362b4066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220ab99e-ef76-4a7e-b42f-645c29cd6b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ResNet: 1-1                            [-1, 10]                  --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 32, 32]          864\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 32, 32]          64\n",
      "|    └─Sequential: 2-3                   [-1, 32, 32, 32]          --\n",
      "|    |    └─BasicBlock: 3-1              [-1, 32, 32, 32]          18,560\n",
      "|    |    └─BasicBlock: 3-2              [-1, 32, 32, 32]          18,560\n",
      "|    └─Sequential: 2-4                   [-1, 64, 16, 16]          --\n",
      "|    |    └─BasicBlock: 3-3              [-1, 64, 16, 16]          57,728\n",
      "|    |    └─BasicBlock: 3-4              [-1, 64, 16, 16]          73,984\n",
      "|    └─Sequential: 2-5                   [-1, 128, 8, 8]           --\n",
      "|    |    └─BasicBlock: 3-5              [-1, 128, 8, 8]           230,144\n",
      "|    |    └─BasicBlock: 3-6              [-1, 128, 8, 8]           295,424\n",
      "|    └─Sequential: 2-6                   [-1, 256, 4, 4]           --\n",
      "|    |    └─BasicBlock: 3-7              [-1, 256, 4, 4]           919,040\n",
      "|    |    └─BasicBlock: 3-8              [-1, 256, 4, 4]           1,180,672\n",
      "|    └─Dropout: 2-7                      [-1, 256]                 --\n",
      "|    └─Linear: 2-8                       [-1, 10]                  2,570\n",
      "==========================================================================================\n",
      "Total params: 2,797,610\n",
      "Trainable params: 2,797,610\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 146.15\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.25\n",
      "Params size (MB): 10.67\n",
      "Estimated Total Size (MB): 14.93\n",
      "==========================================================================================\n",
      "\n",
      "Epoch: 0\n",
      "Training epoch 0: Loss=1.514 Acc=44.266\n",
      "Testing epoch 0: Loss=1.408 Acc=52.680\n",
      "Saving..\n",
      "Epoch 0: 18.11s\n",
      "Train: 16.42s, Test: 1.69s\n",
      "\n",
      "Epoch: 1\n",
      "Training epoch 1: Loss=1.010 Acc=64.100\n",
      "Testing epoch 1: Loss=0.893 Acc=68.730\n",
      "Saving..\n",
      "Epoch 1: 34.97s\n",
      "Train: 15.26s, Test: 1.60s\n",
      "\n",
      "Epoch: 2\n",
      "Training epoch 2: Loss=0.779 Acc=72.578\n",
      "Testing epoch 2: Loss=0.990 Acc=69.080\n",
      "Saving..\n",
      "Epoch 2: 51.89s\n",
      "Train: 15.35s, Test: 1.57s\n",
      "\n",
      "Epoch: 3\n",
      "Training epoch 3: Loss=0.668 Acc=76.856\n",
      "Testing epoch 3: Loss=0.679 Acc=76.870\n",
      "Saving..\n",
      "Epoch 3: 68.92s\n",
      "Train: 15.49s, Test: 1.54s\n",
      "\n",
      "Epoch: 4\n",
      "Training epoch 4: Loss=0.587 Acc=79.508\n",
      "Testing epoch 4: Loss=0.677 Acc=77.500\n",
      "Saving..\n",
      "Epoch 4: 85.88s\n",
      "Train: 15.40s, Test: 1.56s\n",
      "\n",
      "Epoch: 5\n",
      "Training epoch 5: Loss=0.532 Acc=81.570\n",
      "Testing epoch 5: Loss=0.620 Acc=78.880\n",
      "Saving..\n",
      "Epoch 5: 102.96s\n",
      "Train: 15.49s, Test: 1.58s\n",
      "\n",
      "Epoch: 6\n",
      "Training epoch 6: Loss=0.487 Acc=83.274\n",
      "Testing epoch 6: Loss=0.515 Acc=82.600\n",
      "Saving..\n",
      "Epoch 6: 120.08s\n",
      "Train: 15.55s, Test: 1.58s\n",
      "\n",
      "Epoch: 7\n",
      "Training epoch 7: Loss=0.446 Acc=84.632\n",
      "Testing epoch 7: Loss=0.528 Acc=82.880\n",
      "Saving..\n",
      "Epoch 7: 137.15s\n",
      "Train: 15.55s, Test: 1.51s\n",
      "\n",
      "Epoch: 8\n",
      "Training epoch 8: Loss=0.420 Acc=85.362\n",
      "Testing epoch 8: Loss=0.469 Acc=84.140\n",
      "Saving..\n",
      "Epoch 8: 154.36s\n",
      "Train: 15.74s, Test: 1.47s\n",
      "\n",
      "Epoch: 9\n",
      "Training epoch 9: Loss=0.389 Acc=86.408\n",
      "Testing epoch 9: Loss=0.433 Acc=85.760\n",
      "Saving..\n",
      "Epoch 9: 171.66s\n",
      "Train: 15.73s, Test: 1.57s\n",
      "\n",
      "Epoch: 10\n",
      "Training epoch 10: Loss=0.370 Acc=87.320\n",
      "Testing epoch 10: Loss=0.511 Acc=83.840\n",
      "Epoch 10: 188.97s\n",
      "Train: 15.70s, Test: 1.61s\n",
      "\n",
      "Epoch: 11\n",
      "Training epoch 11: Loss=0.350 Acc=87.868\n",
      "Testing epoch 11: Loss=0.446 Acc=85.280\n",
      "Epoch 11: 206.23s\n",
      "Train: 15.70s, Test: 1.56s\n",
      "\n",
      "Epoch: 12\n",
      "Training epoch 12: Loss=0.325 Acc=88.810\n",
      "Testing epoch 12: Loss=0.462 Acc=84.850\n",
      "Epoch 12: 223.41s\n",
      "Train: 15.70s, Test: 1.48s\n",
      "\n",
      "Epoch: 13\n",
      "Training epoch 13: Loss=0.313 Acc=89.082\n",
      "Testing epoch 13: Loss=0.428 Acc=86.220\n",
      "Saving..\n",
      "Epoch 13: 240.82s\n",
      "Train: 15.82s, Test: 1.59s\n",
      "\n",
      "Epoch: 14\n",
      "Training epoch 14: Loss=0.299 Acc=89.572\n",
      "Testing epoch 14: Loss=0.423 Acc=86.310\n",
      "Saving..\n",
      "Epoch 14: 258.22s\n",
      "Train: 15.83s, Test: 1.57s\n",
      "\n",
      "Epoch: 15\n",
      "Training epoch 15: Loss=0.281 Acc=90.292\n",
      "Testing epoch 15: Loss=0.482 Acc=84.710\n",
      "Epoch 15: 275.58s\n",
      "Train: 15.84s, Test: 1.52s\n",
      "\n",
      "Epoch: 16\n",
      "Training epoch 16: Loss=0.271 Acc=90.530\n",
      "Testing epoch 16: Loss=0.414 Acc=86.630\n",
      "Saving..\n",
      "Epoch 16: 293.07s\n",
      "Train: 15.86s, Test: 1.63s\n",
      "\n",
      "Epoch: 17\n",
      "Training epoch 17: Loss=0.253 Acc=91.202\n",
      "Testing epoch 17: Loss=0.398 Acc=87.490\n",
      "Saving..\n",
      "Epoch 17: 310.56s\n",
      "Train: 15.94s, Test: 1.56s\n",
      "\n",
      "Epoch: 18\n",
      "Training epoch 18: Loss=0.246 Acc=91.414\n",
      "Testing epoch 18: Loss=0.452 Acc=85.740\n",
      "Epoch 18: 328.08s\n",
      "Train: 15.97s, Test: 1.55s\n",
      "\n",
      "Epoch: 19\n",
      "Training epoch 19: Loss=0.228 Acc=92.162\n",
      "Testing epoch 19: Loss=0.428 Acc=86.600\n",
      "Epoch 19: 345.55s\n",
      "Train: 15.84s, Test: 1.63s\n",
      "\n",
      "Epoch: 20\n",
      "Training epoch 20: Loss=0.219 Acc=92.378\n",
      "Testing epoch 20: Loss=0.430 Acc=86.500\n",
      "Epoch 20: 362.90s\n",
      "Train: 15.89s, Test: 1.47s\n",
      "\n",
      "Epoch: 21\n",
      "Training epoch 21: Loss=0.216 Acc=92.416\n",
      "Testing epoch 21: Loss=0.413 Acc=87.300\n",
      "Epoch 21: 380.41s\n",
      "Train: 15.90s, Test: 1.61s\n",
      "\n",
      "Epoch: 22\n",
      "Training epoch 22: Loss=0.202 Acc=92.930\n",
      "Testing epoch 22: Loss=0.427 Acc=87.030\n",
      "Epoch 22: 397.82s\n",
      "Train: 15.91s, Test: 1.50s\n",
      "\n",
      "Epoch: 23\n",
      "Training epoch 23: Loss=0.196 Acc=93.074\n",
      "Testing epoch 23: Loss=0.437 Acc=87.490\n",
      "Epoch 23: 415.31s\n",
      "Train: 15.96s, Test: 1.53s\n",
      "\n",
      "Epoch: 24\n",
      "Training epoch 24: Loss=0.187 Acc=93.466\n",
      "Testing epoch 24: Loss=0.387 Acc=88.190\n",
      "Saving..\n",
      "Epoch 24: 432.77s\n",
      "Train: 15.87s, Test: 1.58s\n",
      "\n",
      "Epoch: 25\n",
      "Training epoch 25: Loss=0.178 Acc=93.762\n",
      "Testing epoch 25: Loss=0.395 Acc=88.570\n",
      "Saving..\n",
      "Epoch 25: 450.29s\n",
      "Train: 15.99s, Test: 1.53s\n",
      "\n",
      "Epoch: 26\n",
      "Training epoch 26: Loss=0.172 Acc=93.904\n",
      "Testing epoch 26: Loss=0.361 Acc=88.920\n",
      "Saving..\n",
      "Epoch 26: 467.79s\n",
      "Train: 15.98s, Test: 1.52s\n",
      "\n",
      "Epoch: 27\n",
      "Training epoch 27: Loss=0.163 Acc=94.298\n",
      "Testing epoch 27: Loss=0.378 Acc=88.840\n",
      "Epoch 27: 485.36s\n",
      "Train: 16.01s, Test: 1.56s\n",
      "\n",
      "Epoch: 28\n",
      "Training epoch 28: Loss=0.161 Acc=94.370\n",
      "Testing epoch 28: Loss=0.381 Acc=88.910\n",
      "Epoch 28: 502.87s\n",
      "Train: 15.97s, Test: 1.54s\n",
      "\n",
      "Epoch: 29\n",
      "Training epoch 29: Loss=0.150 Acc=94.672\n",
      "Testing epoch 29: Loss=0.423 Acc=88.060\n",
      "Epoch 29: 520.37s\n",
      "Train: 15.97s, Test: 1.53s\n",
      "\n",
      "Epoch: 30\n",
      "Training epoch 30: Loss=0.147 Acc=94.736\n",
      "Testing epoch 30: Loss=0.382 Acc=89.090\n",
      "Saving..\n",
      "Epoch 30: 537.94s\n",
      "Train: 15.95s, Test: 1.61s\n",
      "\n",
      "Epoch: 31\n",
      "Training epoch 31: Loss=0.139 Acc=95.038\n",
      "Testing epoch 31: Loss=0.377 Acc=89.550\n",
      "Saving..\n",
      "Epoch 31: 555.41s\n",
      "Train: 15.94s, Test: 1.53s\n",
      "\n",
      "Epoch: 32\n",
      "Training epoch 32: Loss=0.133 Acc=95.290\n",
      "Testing epoch 32: Loss=0.388 Acc=89.190\n",
      "Epoch 32: 573.01s\n",
      "Train: 16.01s, Test: 1.59s\n",
      "\n",
      "Epoch: 33\n",
      "Training epoch 33: Loss=0.128 Acc=95.450\n",
      "Testing epoch 33: Loss=0.432 Acc=88.660\n",
      "Epoch 33: 590.57s\n",
      "Train: 16.00s, Test: 1.57s\n",
      "\n",
      "Epoch: 34\n",
      "Training epoch 34: Loss=0.125 Acc=95.592\n",
      "Testing epoch 34: Loss=0.382 Acc=89.350\n",
      "Epoch 34: 608.08s\n",
      "Train: 15.95s, Test: 1.56s\n",
      "\n",
      "Epoch: 35\n",
      "Training epoch 35: Loss=0.119 Acc=95.774\n",
      "Testing epoch 35: Loss=0.364 Acc=89.690\n",
      "Saving..\n",
      "Epoch 35: 625.55s\n",
      "Train: 15.91s, Test: 1.56s\n",
      "\n",
      "Epoch: 36\n",
      "Training epoch 36: Loss=0.117 Acc=95.862\n",
      "Testing epoch 36: Loss=0.389 Acc=89.630\n",
      "Epoch 36: 643.13s\n",
      "Train: 15.99s, Test: 1.60s\n",
      "\n",
      "Epoch: 37\n",
      "Training epoch 37: Loss=0.112 Acc=96.022\n",
      "Testing epoch 37: Loss=0.395 Acc=89.480\n",
      "Epoch 37: 660.58s\n",
      "Train: 15.96s, Test: 1.48s\n",
      "\n",
      "Epoch: 38\n",
      "Training epoch 38: Loss=0.109 Acc=96.238\n",
      "Testing epoch 38: Loss=0.339 Acc=90.580\n",
      "Saving..\n",
      "Epoch 38: 678.12s\n",
      "Train: 15.96s, Test: 1.58s\n",
      "\n",
      "Epoch: 39\n",
      "Training epoch 39: Loss=0.104 Acc=96.294\n",
      "Testing epoch 39: Loss=0.395 Acc=89.500\n",
      "Epoch 39: 695.56s\n",
      "Train: 15.93s, Test: 1.51s\n",
      "\n",
      "Epoch: 40\n",
      "Training epoch 40: Loss=0.101 Acc=96.338\n",
      "Testing epoch 40: Loss=0.402 Acc=89.840\n",
      "Epoch 40: 713.02s\n",
      "Train: 16.01s, Test: 1.45s\n",
      "\n",
      "Epoch: 41\n",
      "Training epoch 41: Loss=0.098 Acc=96.538\n",
      "Testing epoch 41: Loss=0.390 Acc=89.690\n",
      "Epoch 41: 730.46s\n",
      "Train: 15.97s, Test: 1.46s\n",
      "\n",
      "Epoch: 42\n",
      "Training epoch 42: Loss=0.092 Acc=96.678\n",
      "Testing epoch 42: Loss=0.411 Acc=89.920\n",
      "Epoch 42: 747.93s\n",
      "Train: 16.01s, Test: 1.46s\n",
      "\n",
      "Epoch: 43\n",
      "Training epoch 43: Loss=0.085 Acc=96.974\n",
      "Testing epoch 43: Loss=0.427 Acc=89.120\n",
      "Epoch 43: 765.29s\n",
      "Train: 15.87s, Test: 1.49s\n",
      "\n",
      "Epoch: 44\n",
      "Training epoch 44: Loss=0.085 Acc=96.950\n",
      "Testing epoch 44: Loss=0.424 Acc=89.350\n",
      "Epoch 44: 782.72s\n",
      "Train: 15.88s, Test: 1.55s\n",
      "\n",
      "Epoch: 45\n",
      "Training epoch 45: Loss=0.084 Acc=96.966\n",
      "Testing epoch 45: Loss=0.398 Acc=90.020\n",
      "Epoch 45: 800.19s\n",
      "Train: 15.95s, Test: 1.51s\n",
      "\n",
      "Epoch: 46\n",
      "Training epoch 46: Loss=0.081 Acc=97.114\n",
      "Testing epoch 46: Loss=0.417 Acc=89.910\n",
      "Epoch 46: 817.79s\n",
      "Train: 16.01s, Test: 1.59s\n",
      "\n",
      "Epoch: 47\n",
      "Training epoch 47: Loss=0.080 Acc=97.116\n",
      "Testing epoch 47: Loss=0.399 Acc=90.050\n",
      "Epoch 47: 835.33s\n",
      "Train: 15.96s, Test: 1.58s\n",
      "\n",
      "Epoch: 48\n",
      "Training epoch 48: Loss=0.078 Acc=97.330\n",
      "Testing epoch 48: Loss=0.435 Acc=89.760\n",
      "Epoch 48: 852.71s\n",
      "Train: 15.94s, Test: 1.45s\n",
      "\n",
      "Epoch: 49\n",
      "Training epoch 49: Loss=0.075 Acc=97.288\n",
      "Testing epoch 49: Loss=0.433 Acc=89.510\n",
      "Epoch 49: 870.15s\n",
      "Train: 15.95s, Test: 1.48s\n",
      "\n",
      "Epoch: 50\n",
      "Training epoch 50: Loss=0.072 Acc=97.442\n",
      "Testing epoch 50: Loss=0.409 Acc=90.060\n",
      "Epoch 50: 887.64s\n",
      "Train: 15.95s, Test: 1.54s\n",
      "\n",
      "Epoch: 51\n",
      "Training epoch 51: Loss=0.069 Acc=97.594\n",
      "Testing epoch 51: Loss=0.422 Acc=89.800\n",
      "Epoch 51: 905.20s\n",
      "Train: 15.96s, Test: 1.60s\n",
      "\n",
      "Epoch: 52\n",
      "Training epoch 52: Loss=0.068 Acc=97.534\n",
      "Testing epoch 52: Loss=0.402 Acc=90.260\n",
      "Epoch 52: 922.78s\n",
      "Train: 15.99s, Test: 1.59s\n",
      "\n",
      "Epoch: 53\n",
      "Training epoch 53: Loss=0.064 Acc=97.670\n",
      "Testing epoch 53: Loss=0.410 Acc=90.340\n",
      "Epoch 53: 940.25s\n",
      "Train: 15.95s, Test: 1.51s\n",
      "\n",
      "Epoch: 54\n",
      "Training epoch 54: Loss=0.064 Acc=97.718\n",
      "Testing epoch 54: Loss=0.407 Acc=90.420\n",
      "Epoch 54: 957.78s\n",
      "Train: 15.99s, Test: 1.54s\n",
      "\n",
      "Epoch: 55\n",
      "Training epoch 55: Loss=0.061 Acc=97.842\n",
      "Testing epoch 55: Loss=0.417 Acc=90.400\n",
      "Epoch 55: 975.38s\n",
      "Train: 15.98s, Test: 1.61s\n",
      "\n",
      "Epoch: 56\n",
      "Training epoch 56: Loss=0.059 Acc=97.892\n",
      "Testing epoch 56: Loss=0.406 Acc=90.570\n",
      "Epoch 56: 992.88s\n",
      "Train: 15.98s, Test: 1.52s\n",
      "\n",
      "Epoch: 57\n",
      "Training epoch 57: Loss=0.055 Acc=97.974\n",
      "Testing epoch 57: Loss=0.440 Acc=90.220\n",
      "Epoch 57: 1010.51s\n",
      "Train: 16.01s, Test: 1.62s\n",
      "\n",
      "Epoch: 58\n",
      "Training epoch 58: Loss=0.055 Acc=98.096\n",
      "Testing epoch 58: Loss=0.448 Acc=90.110\n",
      "Epoch 58: 1028.10s\n",
      "Train: 16.00s, Test: 1.60s\n",
      "\n",
      "Epoch: 59\n",
      "Training epoch 59: Loss=0.051 Acc=98.168\n",
      "Testing epoch 59: Loss=0.427 Acc=90.340\n",
      "Epoch 59: 1045.63s\n",
      "Train: 16.00s, Test: 1.52s\n",
      "\n",
      "Epoch: 60\n",
      "Training epoch 60: Loss=0.052 Acc=98.196\n",
      "Testing epoch 60: Loss=0.423 Acc=90.730\n",
      "Saving..\n",
      "Epoch 60: 1063.24s\n",
      "Train: 16.02s, Test: 1.59s\n",
      "\n",
      "Epoch: 61\n",
      "Training epoch 61: Loss=0.049 Acc=98.274\n",
      "Testing epoch 61: Loss=0.438 Acc=90.540\n",
      "Epoch 61: 1080.79s\n",
      "Train: 15.98s, Test: 1.57s\n",
      "\n",
      "Epoch: 62\n",
      "Training epoch 62: Loss=0.048 Acc=98.268\n",
      "Testing epoch 62: Loss=0.445 Acc=90.280\n",
      "Epoch 62: 1098.41s\n",
      "Train: 16.00s, Test: 1.62s\n",
      "\n",
      "Epoch: 63\n",
      "Training epoch 63: Loss=0.049 Acc=98.238\n",
      "Testing epoch 63: Loss=0.427 Acc=90.590\n",
      "Epoch 63: 1115.88s\n",
      "Train: 15.98s, Test: 1.48s\n",
      "\n",
      "Epoch: 64\n",
      "Training epoch 64: Loss=0.048 Acc=98.256\n",
      "Testing epoch 64: Loss=0.417 Acc=90.710\n",
      "Epoch 64: 1133.42s\n",
      "Train: 15.94s, Test: 1.60s\n",
      "\n",
      "Epoch: 65\n",
      "Training epoch 65: Loss=0.045 Acc=98.418\n",
      "Testing epoch 65: Loss=0.410 Acc=90.960\n",
      "Saving..\n",
      "Epoch 65: 1150.98s\n",
      "Train: 15.97s, Test: 1.59s\n",
      "\n",
      "Epoch: 66\n",
      "Training epoch 66: Loss=0.047 Acc=98.410\n",
      "Testing epoch 66: Loss=0.426 Acc=90.590\n",
      "Epoch 66: 1168.52s\n",
      "Train: 15.97s, Test: 1.56s\n",
      "\n",
      "Epoch: 67\n",
      "Training epoch 67: Loss=0.044 Acc=98.434\n",
      "Testing epoch 67: Loss=0.445 Acc=90.230\n",
      "Epoch 67: 1186.04s\n",
      "Train: 16.02s, Test: 1.50s\n",
      "\n",
      "Epoch: 68\n",
      "Training epoch 68: Loss=0.040 Acc=98.584\n",
      "Testing epoch 68: Loss=0.427 Acc=90.950\n",
      "Epoch 68: 1203.57s\n",
      "Train: 15.98s, Test: 1.55s\n",
      "\n",
      "Epoch: 69\n",
      "Training epoch 69: Loss=0.041 Acc=98.528\n",
      "Testing epoch 69: Loss=0.422 Acc=90.920\n",
      "Epoch 69: 1221.03s\n",
      "Train: 15.97s, Test: 1.50s\n",
      "\n",
      "Epoch: 70\n",
      "Training epoch 70: Loss=0.039 Acc=98.714\n",
      "Testing epoch 70: Loss=0.441 Acc=90.440\n",
      "Epoch 70: 1238.64s\n",
      "Train: 16.02s, Test: 1.59s\n",
      "\n",
      "Epoch: 71\n",
      "Training epoch 71: Loss=0.037 Acc=98.660\n",
      "Testing epoch 71: Loss=0.440 Acc=90.870\n",
      "Epoch 71: 1256.10s\n",
      "Train: 15.94s, Test: 1.52s\n",
      "\n",
      "Epoch: 72\n",
      "Training epoch 72: Loss=0.036 Acc=98.720\n",
      "Testing epoch 72: Loss=0.442 Acc=90.920\n",
      "Epoch 72: 1273.61s\n",
      "Train: 15.98s, Test: 1.54s\n",
      "\n",
      "Epoch: 73\n",
      "Training epoch 73: Loss=0.042 Acc=98.534\n",
      "Testing epoch 73: Loss=0.445 Acc=90.920\n",
      "Epoch 73: 1291.22s\n",
      "Train: 15.98s, Test: 1.62s\n",
      "\n",
      "Epoch: 74\n",
      "Training epoch 74: Loss=0.037 Acc=98.652\n",
      "Testing epoch 74: Loss=0.465 Acc=90.680\n",
      "Epoch 74: 1308.92s\n",
      "Train: 15.99s, Test: 1.72s\n",
      "\n",
      "Epoch: 75\n",
      "Training epoch 75: Loss=0.035 Acc=98.710\n",
      "Testing epoch 75: Loss=0.462 Acc=90.450\n",
      "Epoch 75: 1326.56s\n",
      "Train: 16.07s, Test: 1.57s\n",
      "\n",
      "Epoch: 76\n",
      "Training epoch 76: Loss=0.033 Acc=98.896\n",
      "Testing epoch 76: Loss=0.452 Acc=90.810\n",
      "Epoch 76: 1343.95s\n",
      "Train: 15.90s, Test: 1.49s\n",
      "\n",
      "Epoch: 77\n",
      "Training epoch 77: Loss=0.031 Acc=98.968\n",
      "Testing epoch 77: Loss=0.455 Acc=91.010\n",
      "Saving..\n",
      "Epoch 77: 1361.48s\n",
      "Train: 15.98s, Test: 1.55s\n",
      "\n",
      "Epoch: 78\n",
      "Training epoch 78: Loss=0.035 Acc=98.788\n",
      "Testing epoch 78: Loss=0.423 Acc=91.240\n",
      "Saving..\n",
      "Epoch 78: 1379.03s\n",
      "Train: 15.98s, Test: 1.58s\n",
      "\n",
      "Epoch: 79\n",
      "Training epoch 79: Loss=0.029 Acc=98.958\n",
      "Testing epoch 79: Loss=0.436 Acc=91.390\n",
      "Saving..\n",
      "Epoch 79: 1396.61s\n",
      "Train: 15.99s, Test: 1.59s\n",
      "\n",
      "Epoch: 80\n",
      "Training epoch 80: Loss=0.035 Acc=98.774\n",
      "Testing epoch 80: Loss=0.460 Acc=90.730\n",
      "Epoch 80: 1414.01s\n",
      "Train: 15.94s, Test: 1.46s\n",
      "\n",
      "Epoch: 81\n",
      "Training epoch 81: Loss=0.032 Acc=98.860\n",
      "Testing epoch 81: Loss=0.472 Acc=90.680\n",
      "Epoch 81: 1431.54s\n",
      "Train: 15.97s, Test: 1.56s\n",
      "\n",
      "Epoch: 82\n",
      "Training epoch 82: Loss=0.032 Acc=98.872\n",
      "Testing epoch 82: Loss=0.445 Acc=91.070\n",
      "Epoch 82: 1448.98s\n",
      "Train: 15.94s, Test: 1.50s\n",
      "\n",
      "Epoch: 83\n",
      "Training epoch 83: Loss=0.030 Acc=98.968\n",
      "Testing epoch 83: Loss=0.471 Acc=90.690\n",
      "Epoch 83: 1466.52s\n",
      "Train: 15.93s, Test: 1.62s\n",
      "\n",
      "Epoch: 84\n",
      "Training epoch 84: Loss=0.032 Acc=98.864\n",
      "Testing epoch 84: Loss=0.452 Acc=90.720\n",
      "Epoch 84: 1484.02s\n",
      "Train: 15.96s, Test: 1.54s\n",
      "\n",
      "Epoch: 85\n",
      "Training epoch 85: Loss=0.024 Acc=99.174\n",
      "Testing epoch 85: Loss=0.462 Acc=91.160\n",
      "Epoch 85: 1501.50s\n",
      "Train: 15.95s, Test: 1.53s\n",
      "\n",
      "Epoch: 86\n",
      "Training epoch 86: Loss=0.028 Acc=99.040\n",
      "Testing epoch 86: Loss=0.472 Acc=91.140\n",
      "Epoch 86: 1519.01s\n",
      "Train: 15.93s, Test: 1.58s\n",
      "\n",
      "Epoch: 87\n",
      "Training epoch 87: Loss=0.026 Acc=99.100\n",
      "Testing epoch 87: Loss=0.462 Acc=91.230\n",
      "Epoch 87: 1536.51s\n",
      "Train: 15.95s, Test: 1.55s\n",
      "\n",
      "Epoch: 88\n",
      "Training epoch 88: Loss=0.029 Acc=98.962\n",
      "Testing epoch 88: Loss=0.508 Acc=90.650\n",
      "Epoch 88: 1553.94s\n",
      "Train: 15.91s, Test: 1.51s\n",
      "\n",
      "Epoch: 89\n",
      "Training epoch 89: Loss=0.026 Acc=99.068\n",
      "Testing epoch 89: Loss=0.444 Acc=91.440\n",
      "Saving..\n",
      "Epoch 89: 1571.38s\n",
      "Train: 15.86s, Test: 1.58s\n",
      "\n",
      "Epoch: 90\n",
      "Training epoch 90: Loss=0.028 Acc=98.986\n",
      "Testing epoch 90: Loss=0.444 Acc=91.390\n",
      "Epoch 90: 1588.79s\n",
      "Train: 15.95s, Test: 1.46s\n",
      "\n",
      "Epoch: 91\n",
      "Training epoch 91: Loss=0.024 Acc=99.218\n",
      "Testing epoch 91: Loss=0.443 Acc=91.290\n",
      "Epoch 91: 1606.20s\n",
      "Train: 15.90s, Test: 1.52s\n",
      "\n",
      "Epoch: 92\n",
      "Training epoch 92: Loss=0.023 Acc=99.170\n",
      "Testing epoch 92: Loss=0.455 Acc=91.240\n",
      "Epoch 92: 1623.66s\n",
      "Train: 15.90s, Test: 1.56s\n",
      "\n",
      "Epoch: 93\n",
      "Training epoch 93: Loss=0.023 Acc=99.200\n",
      "Testing epoch 93: Loss=0.456 Acc=91.100\n",
      "Epoch 93: 1641.15s\n",
      "Train: 15.95s, Test: 1.54s\n",
      "\n",
      "Epoch: 94\n",
      "Training epoch 94: Loss=0.025 Acc=99.144\n",
      "Testing epoch 94: Loss=0.438 Acc=91.330\n",
      "Epoch 94: 1658.51s\n",
      "Train: 15.86s, Test: 1.50s\n",
      "\n",
      "Epoch: 95\n",
      "Training epoch 95: Loss=0.022 Acc=99.194\n",
      "Testing epoch 95: Loss=0.460 Acc=91.050\n",
      "Epoch 95: 1676.04s\n",
      "Train: 15.90s, Test: 1.63s\n",
      "\n",
      "Epoch: 96\n",
      "Training epoch 96: Loss=0.024 Acc=99.162\n",
      "Testing epoch 96: Loss=0.488 Acc=90.660\n",
      "Epoch 96: 1693.64s\n",
      "Train: 15.97s, Test: 1.63s\n",
      "\n",
      "Epoch: 97\n",
      "Training epoch 97: Loss=0.023 Acc=99.226\n",
      "Testing epoch 97: Loss=0.480 Acc=90.930\n",
      "Epoch 97: 1711.14s\n",
      "Train: 16.03s, Test: 1.48s\n",
      "\n",
      "Epoch: 98\n",
      "Training epoch 98: Loss=0.018 Acc=99.354\n",
      "Testing epoch 98: Loss=0.465 Acc=91.150\n",
      "Epoch 98: 1728.68s\n",
      "Train: 16.01s, Test: 1.53s\n",
      "\n",
      "Epoch: 99\n",
      "Training epoch 99: Loss=0.021 Acc=99.284\n",
      "Testing epoch 99: Loss=0.497 Acc=90.550\n",
      "Epoch 99: 1746.25s\n",
      "Train: 16.00s, Test: 1.57s\n",
      "\n",
      "Epoch: 100\n",
      "Training epoch 100: Loss=0.022 Acc=99.242\n",
      "Testing epoch 100: Loss=0.469 Acc=91.280\n",
      "Epoch 100: 1763.76s\n",
      "Train: 15.89s, Test: 1.62s\n",
      "\n",
      "Epoch: 101\n",
      "Training epoch 101: Loss=0.023 Acc=99.222\n",
      "Testing epoch 101: Loss=0.478 Acc=90.790\n",
      "Epoch 101: 1781.29s\n",
      "Train: 15.91s, Test: 1.62s\n",
      "\n",
      "Epoch: 102\n",
      "Training epoch 102: Loss=0.019 Acc=99.346\n",
      "Testing epoch 102: Loss=0.469 Acc=91.480\n",
      "Saving..\n",
      "Epoch 102: 1799.07s\n",
      "Train: 16.05s, Test: 1.72s\n",
      "\n",
      "Epoch: 103\n",
      "Training epoch 103: Loss=0.021 Acc=99.238\n",
      "Testing epoch 103: Loss=0.462 Acc=91.440\n",
      "Epoch 103: 1816.80s\n",
      "Train: 16.13s, Test: 1.60s\n",
      "\n",
      "Epoch: 104\n",
      "Training epoch 104: Loss=0.022 Acc=99.248\n",
      "Testing epoch 104: Loss=0.484 Acc=91.040\n",
      "Epoch 104: 1834.51s\n",
      "Train: 16.05s, Test: 1.66s\n",
      "\n",
      "Epoch: 105\n",
      "Training epoch 105: Loss=0.018 Acc=99.344\n",
      "Testing epoch 105: Loss=0.492 Acc=90.960\n",
      "Epoch 105: 1852.04s\n",
      "Train: 16.01s, Test: 1.52s\n",
      "\n",
      "Epoch: 106\n",
      "Training epoch 106: Loss=0.021 Acc=99.262\n",
      "Testing epoch 106: Loss=0.514 Acc=91.060\n",
      "Epoch 106: 1869.62s\n",
      "Train: 16.02s, Test: 1.57s\n",
      "\n",
      "Epoch: 107\n",
      "Training epoch 107: Loss=0.021 Acc=99.256\n",
      "Testing epoch 107: Loss=0.493 Acc=91.210\n",
      "Epoch 107: 1887.08s\n",
      "Train: 15.91s, Test: 1.55s\n",
      "\n",
      "Epoch: 108\n",
      "Training epoch 108: Loss=0.020 Acc=99.274\n",
      "Testing epoch 108: Loss=0.500 Acc=91.040\n",
      "Epoch 108: 1904.59s\n",
      "Train: 15.94s, Test: 1.56s\n",
      "\n",
      "Epoch: 109\n",
      "Training epoch 109: Loss=0.017 Acc=99.416\n",
      "Testing epoch 109: Loss=0.481 Acc=91.310\n",
      "Epoch 109: 1922.20s\n",
      "Train: 15.94s, Test: 1.67s\n",
      "\n",
      "Epoch: 110\n",
      "Training epoch 110: Loss=0.018 Acc=99.390\n",
      "Testing epoch 110: Loss=0.478 Acc=91.430\n",
      "Epoch 110: 1939.66s\n",
      "Train: 15.91s, Test: 1.55s\n",
      "\n",
      "Epoch: 111\n",
      "Training epoch 111: Loss=0.018 Acc=99.390\n",
      "Testing epoch 111: Loss=0.490 Acc=91.270\n",
      "Epoch 111: 1957.20s\n",
      "Train: 15.98s, Test: 1.56s\n",
      "\n",
      "Epoch: 112\n",
      "Training epoch 112: Loss=0.018 Acc=99.378\n",
      "Testing epoch 112: Loss=0.505 Acc=90.990\n",
      "Epoch 112: 1974.53s\n",
      "Train: 15.86s, Test: 1.47s\n",
      "\n",
      "Epoch: 113\n",
      "Training epoch 113: Loss=0.019 Acc=99.326\n",
      "Testing epoch 113: Loss=0.479 Acc=91.210\n",
      "Epoch 113: 1992.01s\n",
      "Train: 15.89s, Test: 1.59s\n",
      "\n",
      "Epoch: 114\n",
      "Training epoch 114: Loss=0.019 Acc=99.320\n",
      "Testing epoch 114: Loss=0.503 Acc=91.050\n",
      "Epoch 114: 2009.62s\n",
      "Train: 16.02s, Test: 1.59s\n",
      "\n",
      "Epoch: 115\n",
      "Training epoch 115: Loss=0.018 Acc=99.412\n",
      "Testing epoch 115: Loss=0.498 Acc=91.080\n",
      "Epoch 115: 2027.23s\n",
      "Train: 16.01s, Test: 1.60s\n",
      "\n",
      "Epoch: 116\n",
      "Training epoch 116: Loss=0.018 Acc=99.422\n",
      "Testing epoch 116: Loss=0.487 Acc=91.220\n",
      "Epoch 116: 2044.76s\n",
      "Train: 15.93s, Test: 1.61s\n",
      "\n",
      "Epoch: 117\n",
      "Training epoch 117: Loss=0.018 Acc=99.356\n",
      "Testing epoch 117: Loss=0.481 Acc=91.440\n",
      "Epoch 117: 2062.16s\n",
      "Train: 15.92s, Test: 1.48s\n",
      "\n",
      "Epoch: 118\n",
      "Training epoch 118: Loss=0.017 Acc=99.436\n",
      "Testing epoch 118: Loss=0.458 Acc=91.610\n",
      "Saving..\n",
      "Epoch 118: 2079.56s\n",
      "Train: 15.81s, Test: 1.59s\n",
      "\n",
      "Epoch: 119\n",
      "Training epoch 119: Loss=0.014 Acc=99.554\n",
      "Testing epoch 119: Loss=0.486 Acc=91.470\n",
      "Epoch 119: 2096.98s\n",
      "Train: 15.86s, Test: 1.56s\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "# parser.add_argument('--resume', '-r', action='store_true',\n",
    "#                     help='resume from checkpoint')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "Learning_rate = 0.0001\n",
    "Resume = False\n",
    "Optimizer = 'sgd'  # sgd, sgdn, adagrad, adadelta or adam\n",
    "Batch_size = 128\n",
    "\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=Batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if Resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.SGD(net.parameters(), lr=Learning_rate,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "if Optimizer == 'sgdn':\n",
    "    optimizer = optim.SGD(net.parameters(), lr=Learning_rate,\n",
    "                    momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "elif Optimizer == 'adagrad':\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=Learning_rate,\n",
    "                              weight_decay=5e-4)\n",
    "elif Optimizer == 'adadelta':\n",
    "    optimizer = optim.Adadelta(net.parameters(), lr=Learning_rate,\n",
    "                               weight_decay=5e-4)\n",
    "elif Optimizer == 'adam':\n",
    "    optimizer = optim.Adam(net.parameters(), lr=Learning_rate,\n",
    "                           weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "torchsummary.summary(net, (3, 32, 32))\n",
    "\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_training_time = 0\n",
    "    time1 = torch.cuda.Event(enable_timing=True)\n",
    "    time2 = torch.cuda.Event(enable_timing=True)\n",
    "    time1.record()\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        time2.record()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        total_training_time += time1.elapsed_time(time2)\n",
    "        \n",
    "    avg_loss = train_loss/total\n",
    "    acc = 100.*correct/total\n",
    "    print('Training epoch %d: Loss=%.3f Acc=%.3f' %\n",
    "          (epoch, avg_loss, acc))\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    avg_loss = test_loss/total\n",
    "    acc = 100.*correct/total\n",
    "    print('Testing epoch %d: Loss=%.3f Acc=%.3f' %\n",
    "          (epoch, avg_loss, acc))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "filename = Optimizer + '_' + str(Batch_size) + '_' + str(Learning_rate) + '_dropout.csv'\n",
    "file = open(filename, 'w')\n",
    "file.write('train_avg_loss, train_acc, test_avg_loss, test_acc, train_time, test_time\\n')\n",
    "Start_time = time.perf_counter()\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "for epoch in range(start_epoch, start_epoch+120):\n",
    "    time1 = time.perf_counter()\n",
    "    train_avg_loss, train_acc = train(epoch)\n",
    "    time2 = time.perf_counter()\n",
    "    test_avg_loss, test_acc = test(epoch)\n",
    "    Cur_time = time.perf_counter()\n",
    "    # scheduler.step()\n",
    "    train_acc_history.append(train_acc)\n",
    "    test_acc_history.append(test_acc)\n",
    "    print('Epoch %d: %.2fs' % (epoch, Cur_time - Start_time))\n",
    "    print('Train: %.2fs, Test: %.2fs' % (time2 - time1, Cur_time - time2))\n",
    "    file.write('%.3f, %.3f, %.3f, %.3f, %.2f, %.2f\\n' %\n",
    "               (train_avg_loss, train_acc, test_avg_loss, test_acc,\n",
    "                time2 - time1, Cur_time - time2))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68f0b31-f395-46c9-876c-a07fb748e04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f85990c1430>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(120),train_acc_history,'-',linewidth=3,label='Train accuracy')\n",
    "plt.plot(range(120),test_acc_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e227f-a986-4a6d-a8d3-048eb02496e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
