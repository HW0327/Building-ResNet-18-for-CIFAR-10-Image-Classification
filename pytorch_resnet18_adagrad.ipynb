{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0ac129-4b37-4804-8613-3b639d238c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
      "  libsqlite          conda-forge/linux-64::libsqlite-3.40.0-h753d276_0\n",
      "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4\n",
      "  toolz              conda-forge/noarch::toolz-0.12.0-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  chardet-4.0.0-py39hf3d152e_1\n",
      "  libstdcxx-ng-11.2.0-he4da1e4_9\n",
      "  six-1.16.0-pyh6c4a22f_0\n",
      "  zlib-1.2.11-h516909a_1010\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  _openmp_mutex                                   4.5-1_gnu --> 4.5-2_gnu\n",
      "  brotlipy                          0.7.0-py39h3811e60_1001 --> 0.7.0-py39hb9d737c_1005\n",
      "  ca-certificates                      2021.5.30-ha878542_0 --> 2022.9.24-ha878542_0\n",
      "  certifi            conda-forge/linux-64::certifi-2021.5.~ --> conda-forge/noarch::certifi-2022.9.24-pyhd8ed1ab_0\n",
      "  cffi                                1.14.6-py39h4bc2ebd_1 --> 1.15.1-py39he91dace_2\n",
      "  charset-normalizer                     2.0.0-pyhd8ed1ab_0 --> 2.1.1-pyhd8ed1ab_0\n",
      "  colorama                               0.4.4-pyh9f0ad1d_0 --> 0.4.6-pyhd8ed1ab_0\n",
      "  conda                               4.10.3-py39hf3d152e_2 --> 22.9.0-py39hf3d152e_2\n",
      "  conda-package-han~                   1.7.3-py39h3811e60_0 --> 1.9.0-py39hb9d737c_1\n",
      "  cryptography                         3.4.7-py39hbca0aa6_0 --> 38.0.3-py39h3ccb8fc_0\n",
      "  idna                                     3.1-pyhd3deb0d_0 --> 3.4-pyhd8ed1ab_0\n",
      "  ld_impl_linux-64                        2.36.1-hea4e1c9_2 --> 2.39-hcc3a1bd_1\n",
      "  libffi                                   3.4.2-h9c3ff4c_4 --> 3.4.2-h7f98852_5\n",
      "  libgcc-ng                               11.2.0-h1d223b6_9 --> 12.2.0-h65d4601_19\n",
      "  libgomp                                 11.2.0-h1d223b6_9 --> 12.2.0-h65d4601_19\n",
      "  ncurses                                    6.2-h58526e2_4 --> 6.3-h27087fc_1\n",
      "  openssl                                 1.1.1l-h7f98852_0 --> 3.0.7-h166bdaf_0\n",
      "  pycosat                           0.6.3-py39h3811e60_1006 --> 0.6.4-py39hb9d737c_1\n",
      "  pycparser                               2.20-pyh9f0ad1d_2 --> 2.21-pyhd8ed1ab_0\n",
      "  pyopenssl                             20.0.1-pyhd8ed1ab_0 --> 22.1.0-pyhd8ed1ab_0\n",
      "  pysocks            conda-forge/linux-64::pysocks-1.7.1-p~ --> conda-forge/noarch::pysocks-1.7.1-pyha2e5f31_6\n",
      "  python                           3.9.7-hb7a2778_2_cpython --> 3.9.13-h2660328_0_cpython\n",
      "  readline                                   8.1-h46c0cb4_0 --> 8.1.2-h0f457ee_0\n",
      "  requests                              2.26.0-pyhd8ed1ab_0 --> 2.28.1-pyhd8ed1ab_1\n",
      "  ruamel_yaml                     0.15.80-py39h3811e60_1004 --> 0.15.80-py39hb9d737c_1008\n",
      "  setuptools         conda-forge/linux-64::setuptools-58.0~ --> conda-forge/noarch::setuptools-65.5.1-pyhd8ed1ab_0\n",
      "  sqlite                                  3.36.0-h9cd32fc_2 --> 3.40.0-h4ff8645_0\n",
      "  tk                                      8.6.11-h27826a3_1 --> 8.6.12-h27826a3_0\n",
      "  tqdm                                  4.62.3-pyhd8ed1ab_0 --> 4.64.1-pyhd8ed1ab_0\n",
      "  tzdata                                   2021a-he74cb21_1 --> 2022f-h191b570_0\n",
      "  urllib3                               1.26.7-pyhd8ed1ab_0 --> 1.26.11-pyhd8ed1ab_0\n",
      "  wheel                                 0.37.0-pyhd8ed1ab_1 --> 0.38.4-pyhd8ed1ab_0\n",
      "  xz                                       5.2.5-h516909a_1 --> 5.2.6-h166bdaf_0\n",
      "  yaml                                     0.2.5-h516909a_0 --> 0.2.5-h7f98852_2\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /opt/conda\n",
      "  uid: 1000\n",
      "  gid: 100\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch-summary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda update -n base conda\n",
    "%conda install pytorch\n",
    "%conda install torchvision\n",
    "%pip install torch-summary\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe482f3-2fa2-47d3-ab9b-0e1616293a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchsummary\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "551c0cf9-162e-42d1-a813-e58d4871c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "\n",
    "# _, term_width = os.popen('stty size', 'r').read().split()\n",
    "term_width = 50\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8107b7-5d71-4168-88ad-ca44e8e1ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2688f85b-1fc7-48a0-b1f6-0373074e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb8fbf6-ee1d-4fd3-bfc1-62dd014c5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a50d30e2-ae7f-44ed-a9ef-8b6362b4066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "220ab99e-ef76-4a7e-b42f-645c29cd6b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ResNet: 1-1                            [-1, 10]                  --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 32, 32]          864\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 32, 32]          64\n",
      "|    └─Sequential: 2-3                   [-1, 32, 32, 32]          --\n",
      "|    |    └─BasicBlock: 3-1              [-1, 32, 32, 32]          18,560\n",
      "|    |    └─BasicBlock: 3-2              [-1, 32, 32, 32]          18,560\n",
      "|    └─Sequential: 2-4                   [-1, 64, 16, 16]          --\n",
      "|    |    └─BasicBlock: 3-3              [-1, 64, 16, 16]          57,728\n",
      "|    |    └─BasicBlock: 3-4              [-1, 64, 16, 16]          73,984\n",
      "|    └─Sequential: 2-5                   [-1, 128, 8, 8]           --\n",
      "|    |    └─BasicBlock: 3-5              [-1, 128, 8, 8]           230,144\n",
      "|    |    └─BasicBlock: 3-6              [-1, 128, 8, 8]           295,424\n",
      "|    └─Sequential: 2-6                   [-1, 256, 4, 4]           --\n",
      "|    |    └─BasicBlock: 3-7              [-1, 256, 4, 4]           919,040\n",
      "|    |    └─BasicBlock: 3-8              [-1, 256, 4, 4]           1,180,672\n",
      "|    └─Dropout: 2-7                      [-1, 256]                 --\n",
      "|    └─Linear: 2-8                       [-1, 10]                  2,570\n",
      "==========================================================================================\n",
      "Total params: 2,797,610\n",
      "Trainable params: 2,797,610\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 146.15\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.25\n",
      "Params size (MB): 10.67\n",
      "Estimated Total Size (MB): 14.93\n",
      "==========================================================================================\n",
      "\n",
      "Epoch: 0\n",
      "Training epoch 0: Loss=1.924 Acc=28.414\n",
      "Testing epoch 0: Loss=1.711 Acc=36.530\n",
      "Saving..\n",
      "Epoch 0: 16.90s\n",
      "Train: 15.28s, Test: 1.61s\n",
      "\n",
      "Epoch: 1\n",
      "Training epoch 1: Loss=1.730 Acc=35.504\n",
      "Testing epoch 1: Loss=1.606 Acc=40.010\n",
      "Saving..\n",
      "Epoch 1: 33.65s\n",
      "Train: 15.19s, Test: 1.56s\n",
      "\n",
      "Epoch: 2\n",
      "Training epoch 2: Loss=1.660 Acc=38.036\n",
      "Testing epoch 2: Loss=1.557 Acc=41.600\n",
      "Saving..\n",
      "Epoch 2: 50.49s\n",
      "Train: 15.24s, Test: 1.60s\n",
      "\n",
      "Epoch: 3\n",
      "Training epoch 3: Loss=1.616 Acc=39.980\n",
      "Testing epoch 3: Loss=1.524 Acc=42.900\n",
      "Saving..\n",
      "Epoch 3: 67.74s\n",
      "Train: 15.50s, Test: 1.74s\n",
      "\n",
      "Epoch: 4\n",
      "Training epoch 4: Loss=1.583 Acc=41.140\n",
      "Testing epoch 4: Loss=1.488 Acc=44.270\n",
      "Saving..\n",
      "Epoch 4: 85.20s\n",
      "Train: 15.72s, Test: 1.75s\n",
      "\n",
      "Epoch: 5\n",
      "Training epoch 5: Loss=1.559 Acc=42.266\n",
      "Testing epoch 5: Loss=1.463 Acc=45.420\n",
      "Saving..\n",
      "Epoch 5: 102.56s\n",
      "Train: 15.61s, Test: 1.75s\n",
      "\n",
      "Epoch: 6\n",
      "Training epoch 6: Loss=1.536 Acc=43.328\n",
      "Testing epoch 6: Loss=1.443 Acc=46.380\n",
      "Saving..\n",
      "Epoch 6: 131.35s\n",
      "Train: 26.13s, Test: 2.66s\n",
      "\n",
      "Epoch: 7\n",
      "Training epoch 7: Loss=1.518 Acc=44.252\n",
      "Testing epoch 7: Loss=1.434 Acc=46.530\n",
      "Saving..\n",
      "Epoch 7: 163.30s\n",
      "Train: 29.16s, Test: 2.78s\n",
      "\n",
      "Epoch: 8\n",
      "Training epoch 8: Loss=1.500 Acc=44.542\n",
      "Testing epoch 8: Loss=1.414 Acc=47.450\n",
      "Saving..\n",
      "Epoch 8: 195.48s\n",
      "Train: 29.44s, Test: 2.74s\n",
      "\n",
      "Epoch: 9\n",
      "Training epoch 9: Loss=1.488 Acc=45.338\n",
      "Testing epoch 9: Loss=1.404 Acc=48.140\n",
      "Saving..\n",
      "Epoch 9: 228.08s\n",
      "Train: 29.21s, Test: 3.39s\n",
      "\n",
      "Epoch: 10\n",
      "Training epoch 10: Loss=1.474 Acc=45.978\n",
      "Testing epoch 10: Loss=1.395 Acc=48.430\n",
      "Saving..\n",
      "Epoch 10: 260.84s\n",
      "Train: 29.54s, Test: 3.22s\n",
      "\n",
      "Epoch: 11\n",
      "Training epoch 11: Loss=1.465 Acc=46.158\n",
      "Testing epoch 11: Loss=1.383 Acc=48.970\n",
      "Saving..\n",
      "Epoch 11: 294.47s\n",
      "Train: 29.79s, Test: 3.85s\n",
      "\n",
      "Epoch: 12\n",
      "Training epoch 12: Loss=1.453 Acc=47.056\n",
      "Testing epoch 12: Loss=1.369 Acc=49.520\n",
      "Saving..\n",
      "Epoch 12: 336.15s\n",
      "Train: 36.79s, Test: 4.89s\n",
      "\n",
      "Epoch: 13\n",
      "Training epoch 13: Loss=1.442 Acc=47.182\n",
      "Testing epoch 13: Loss=1.357 Acc=50.110\n",
      "Saving..\n",
      "Epoch 13: 384.57s\n",
      "Train: 43.68s, Test: 4.74s\n",
      "\n",
      "Epoch: 14\n",
      "Training epoch 14: Loss=1.431 Acc=47.430\n",
      "Testing epoch 14: Loss=1.348 Acc=50.460\n",
      "Saving..\n",
      "Epoch 14: 444.75s\n",
      "Train: 55.26s, Test: 4.92s\n",
      "\n",
      "Epoch: 15\n",
      "Training epoch 15: Loss=1.424 Acc=47.870\n",
      "Testing epoch 15: Loss=1.344 Acc=50.600\n",
      "Saving..\n",
      "Epoch 15: 478.09s\n",
      "Train: 30.66s, Test: 2.68s\n",
      "\n",
      "Epoch: 16\n",
      "Training epoch 16: Loss=1.415 Acc=48.322\n",
      "Testing epoch 16: Loss=1.333 Acc=50.970\n",
      "Saving..\n",
      "Epoch 16: 510.76s\n",
      "Train: 30.07s, Test: 2.60s\n",
      "\n",
      "Epoch: 17\n",
      "Training epoch 17: Loss=1.407 Acc=48.602\n",
      "Testing epoch 17: Loss=1.326 Acc=51.430\n",
      "Saving..\n",
      "Epoch 17: 543.56s\n",
      "Train: 30.29s, Test: 2.51s\n",
      "\n",
      "Epoch: 18\n",
      "Training epoch 18: Loss=1.397 Acc=49.074\n",
      "Testing epoch 18: Loss=1.320 Acc=51.680\n",
      "Saving..\n",
      "Epoch 18: 576.33s\n",
      "Train: 30.24s, Test: 2.53s\n",
      "\n",
      "Epoch: 19\n",
      "Training epoch 19: Loss=1.393 Acc=49.058\n",
      "Testing epoch 19: Loss=1.315 Acc=51.800\n",
      "Saving..\n",
      "Epoch 19: 608.83s\n",
      "Train: 29.94s, Test: 2.56s\n",
      "\n",
      "Epoch: 20\n",
      "Training epoch 20: Loss=1.386 Acc=49.578\n",
      "Testing epoch 20: Loss=1.310 Acc=52.010\n",
      "Saving..\n",
      "Epoch 20: 641.28s\n",
      "Train: 29.73s, Test: 2.72s\n",
      "\n",
      "Epoch: 21\n",
      "Training epoch 21: Loss=1.377 Acc=49.802\n",
      "Testing epoch 21: Loss=1.304 Acc=52.370\n",
      "Saving..\n",
      "Epoch 21: 673.69s\n",
      "Train: 29.55s, Test: 2.85s\n",
      "\n",
      "Epoch: 22\n",
      "Training epoch 22: Loss=1.373 Acc=50.030\n",
      "Testing epoch 22: Loss=1.297 Acc=52.680\n",
      "Saving..\n",
      "Epoch 22: 705.85s\n",
      "Train: 29.45s, Test: 2.71s\n",
      "\n",
      "Epoch: 23\n",
      "Training epoch 23: Loss=1.365 Acc=50.300\n",
      "Testing epoch 23: Loss=1.292 Acc=52.870\n",
      "Saving..\n",
      "Epoch 23: 738.15s\n",
      "Train: 29.65s, Test: 2.65s\n",
      "\n",
      "Epoch: 24\n",
      "Training epoch 24: Loss=1.361 Acc=50.572\n",
      "Testing epoch 24: Loss=1.289 Acc=52.970\n",
      "Saving..\n",
      "Epoch 24: 770.58s\n",
      "Train: 29.54s, Test: 2.89s\n",
      "\n",
      "Epoch: 25\n",
      "Training epoch 25: Loss=1.354 Acc=50.774\n",
      "Testing epoch 25: Loss=1.281 Acc=53.190\n",
      "Saving..\n",
      "Epoch 25: 802.89s\n",
      "Train: 29.65s, Test: 2.66s\n",
      "\n",
      "Epoch: 26\n",
      "Training epoch 26: Loss=1.348 Acc=51.288\n",
      "Testing epoch 26: Loss=1.279 Acc=53.560\n",
      "Saving..\n",
      "Epoch 26: 835.13s\n",
      "Train: 29.61s, Test: 2.63s\n",
      "\n",
      "Epoch: 27\n",
      "Training epoch 27: Loss=1.346 Acc=51.264\n",
      "Testing epoch 27: Loss=1.274 Acc=53.620\n",
      "Saving..\n",
      "Epoch 27: 867.59s\n",
      "Train: 29.69s, Test: 2.77s\n",
      "\n",
      "Epoch: 28\n",
      "Training epoch 28: Loss=1.339 Acc=51.676\n",
      "Testing epoch 28: Loss=1.270 Acc=53.810\n",
      "Saving..\n",
      "Epoch 28: 899.75s\n",
      "Train: 29.49s, Test: 2.68s\n",
      "\n",
      "Epoch: 29\n",
      "Training epoch 29: Loss=1.336 Acc=51.704\n",
      "Testing epoch 29: Loss=1.265 Acc=54.140\n",
      "Saving..\n",
      "Epoch 29: 932.20s\n",
      "Train: 29.66s, Test: 2.79s\n",
      "\n",
      "Epoch: 30\n",
      "Training epoch 30: Loss=1.331 Acc=51.768\n",
      "Testing epoch 30: Loss=1.262 Acc=54.080\n",
      "Epoch 30: 964.60s\n",
      "Train: 29.54s, Test: 2.86s\n",
      "\n",
      "Epoch: 31\n",
      "Training epoch 31: Loss=1.326 Acc=52.054\n",
      "Testing epoch 31: Loss=1.259 Acc=54.350\n",
      "Saving..\n",
      "Epoch 31: 997.00s\n",
      "Train: 29.48s, Test: 2.93s\n",
      "\n",
      "Epoch: 32\n",
      "Training epoch 32: Loss=1.321 Acc=52.364\n",
      "Testing epoch 32: Loss=1.252 Acc=54.590\n",
      "Saving..\n",
      "Epoch 32: 1029.22s\n",
      "Train: 29.49s, Test: 2.72s\n",
      "\n",
      "Epoch: 33\n",
      "Training epoch 33: Loss=1.316 Acc=52.344\n",
      "Testing epoch 33: Loss=1.248 Acc=54.790\n",
      "Saving..\n",
      "Epoch 33: 1061.48s\n",
      "Train: 29.45s, Test: 2.82s\n",
      "\n",
      "Epoch: 34\n",
      "Training epoch 34: Loss=1.316 Acc=52.378\n",
      "Testing epoch 34: Loss=1.246 Acc=54.860\n",
      "Saving..\n",
      "Epoch 34: 1093.81s\n",
      "Train: 29.68s, Test: 2.65s\n",
      "\n",
      "Epoch: 35\n",
      "Training epoch 35: Loss=1.308 Acc=52.634\n",
      "Testing epoch 35: Loss=1.243 Acc=54.950\n",
      "Saving..\n",
      "Epoch 35: 1126.15s\n",
      "Train: 29.54s, Test: 2.79s\n",
      "\n",
      "Epoch: 36\n",
      "Training epoch 36: Loss=1.305 Acc=52.942\n",
      "Testing epoch 36: Loss=1.238 Acc=55.220\n",
      "Saving..\n",
      "Epoch 36: 1158.53s\n",
      "Train: 29.58s, Test: 2.80s\n",
      "\n",
      "Epoch: 37\n",
      "Training epoch 37: Loss=1.301 Acc=52.808\n",
      "Testing epoch 37: Loss=1.235 Acc=55.210\n",
      "Epoch 37: 1190.90s\n",
      "Train: 29.57s, Test: 2.80s\n",
      "\n",
      "Epoch: 38\n",
      "Training epoch 38: Loss=1.297 Acc=53.088\n",
      "Testing epoch 38: Loss=1.232 Acc=55.430\n",
      "Saving..\n",
      "Epoch 38: 1223.06s\n",
      "Train: 29.40s, Test: 2.76s\n",
      "\n",
      "Epoch: 39\n",
      "Training epoch 39: Loss=1.292 Acc=53.380\n",
      "Testing epoch 39: Loss=1.228 Acc=55.490\n",
      "Saving..\n",
      "Epoch 39: 1255.17s\n",
      "Train: 29.39s, Test: 2.71s\n",
      "\n",
      "Epoch: 40\n",
      "Training epoch 40: Loss=1.290 Acc=53.384\n",
      "Testing epoch 40: Loss=1.225 Acc=55.680\n",
      "Saving..\n",
      "Epoch 40: 1287.42s\n",
      "Train: 29.55s, Test: 2.70s\n",
      "\n",
      "Epoch: 41\n",
      "Training epoch 41: Loss=1.283 Acc=53.854\n",
      "Testing epoch 41: Loss=1.223 Acc=55.650\n",
      "Epoch 41: 1319.69s\n",
      "Train: 29.60s, Test: 2.68s\n",
      "\n",
      "Epoch: 42\n",
      "Training epoch 42: Loss=1.283 Acc=53.630\n",
      "Testing epoch 42: Loss=1.220 Acc=56.000\n",
      "Saving..\n",
      "Epoch 42: 1352.32s\n",
      "Train: 29.80s, Test: 2.83s\n",
      "\n",
      "Epoch: 43\n",
      "Training epoch 43: Loss=1.279 Acc=53.712\n",
      "Testing epoch 43: Loss=1.216 Acc=56.280\n",
      "Saving..\n",
      "Epoch 43: 1384.53s\n",
      "Train: 29.46s, Test: 2.75s\n",
      "\n",
      "Epoch: 44\n",
      "Training epoch 44: Loss=1.278 Acc=53.858\n",
      "Testing epoch 44: Loss=1.214 Acc=56.190\n",
      "Epoch 44: 1416.82s\n",
      "Train: 29.65s, Test: 2.63s\n",
      "\n",
      "Epoch: 45\n",
      "Training epoch 45: Loss=1.269 Acc=54.218\n",
      "Testing epoch 45: Loss=1.213 Acc=56.240\n",
      "Epoch 45: 1448.94s\n",
      "Train: 29.54s, Test: 2.58s\n",
      "\n",
      "Epoch: 46\n",
      "Training epoch 46: Loss=1.271 Acc=54.062\n",
      "Testing epoch 46: Loss=1.209 Acc=56.480\n",
      "Saving..\n",
      "Epoch 46: 1481.06s\n",
      "Train: 29.49s, Test: 2.64s\n",
      "\n",
      "Epoch: 47\n",
      "Training epoch 47: Loss=1.265 Acc=54.558\n",
      "Testing epoch 47: Loss=1.207 Acc=56.410\n",
      "Epoch 47: 1513.59s\n",
      "Train: 29.79s, Test: 2.74s\n",
      "\n",
      "Epoch: 48\n",
      "Training epoch 48: Loss=1.265 Acc=54.448\n",
      "Testing epoch 48: Loss=1.202 Acc=56.760\n",
      "Saving..\n",
      "Epoch 48: 1545.76s\n",
      "Train: 29.43s, Test: 2.74s\n",
      "\n",
      "Epoch: 49\n",
      "Training epoch 49: Loss=1.259 Acc=54.578\n",
      "Testing epoch 49: Loss=1.200 Acc=56.690\n",
      "Epoch 49: 1578.10s\n",
      "Train: 29.56s, Test: 2.79s\n",
      "\n",
      "Epoch: 50\n",
      "Training epoch 50: Loss=1.254 Acc=54.726\n",
      "Testing epoch 50: Loss=1.201 Acc=56.610\n",
      "Epoch 50: 1610.54s\n",
      "Train: 29.86s, Test: 2.57s\n",
      "\n",
      "Epoch: 51\n",
      "Training epoch 51: Loss=1.250 Acc=55.046\n",
      "Testing epoch 51: Loss=1.195 Acc=57.010\n",
      "Saving..\n",
      "Epoch 51: 1642.79s\n",
      "Train: 29.77s, Test: 2.48s\n",
      "\n",
      "Epoch: 52\n",
      "Training epoch 52: Loss=1.250 Acc=55.044\n",
      "Testing epoch 52: Loss=1.191 Acc=56.950\n",
      "Epoch 52: 1675.13s\n",
      "Train: 29.89s, Test: 2.45s\n",
      "\n",
      "Epoch: 53\n",
      "Training epoch 53: Loss=1.249 Acc=55.140\n",
      "Testing epoch 53: Loss=1.191 Acc=57.030\n",
      "Saving..\n",
      "Epoch 53: 1708.09s\n",
      "Train: 30.46s, Test: 2.50s\n",
      "\n",
      "Epoch: 54\n",
      "Training epoch 54: Loss=1.241 Acc=55.340\n",
      "Testing epoch 54: Loss=1.188 Acc=57.180\n",
      "Saving..\n",
      "Epoch 54: 1741.09s\n",
      "Train: 30.38s, Test: 2.62s\n",
      "\n",
      "Epoch: 55\n",
      "Training epoch 55: Loss=1.241 Acc=55.704\n",
      "Testing epoch 55: Loss=1.185 Acc=57.190\n",
      "Saving..\n",
      "Epoch 55: 1773.74s\n",
      "Train: 29.98s, Test: 2.66s\n",
      "\n",
      "Epoch: 56\n",
      "Training epoch 56: Loss=1.242 Acc=55.236\n",
      "Testing epoch 56: Loss=1.187 Acc=57.360\n",
      "Saving..\n",
      "Epoch 56: 1806.16s\n",
      "Train: 29.61s, Test: 2.82s\n",
      "\n",
      "Epoch: 57\n",
      "Training epoch 57: Loss=1.237 Acc=55.716\n",
      "Testing epoch 57: Loss=1.184 Acc=57.570\n",
      "Saving..\n",
      "Epoch 57: 1838.37s\n",
      "Train: 29.43s, Test: 2.78s\n",
      "\n",
      "Epoch: 58\n",
      "Training epoch 58: Loss=1.236 Acc=55.516\n",
      "Testing epoch 58: Loss=1.180 Acc=57.550\n",
      "Epoch 58: 1870.99s\n",
      "Train: 29.63s, Test: 2.99s\n",
      "\n",
      "Epoch: 59\n",
      "Training epoch 59: Loss=1.232 Acc=55.584\n",
      "Testing epoch 59: Loss=1.176 Acc=57.720\n",
      "Saving..\n",
      "Epoch 59: 1903.23s\n",
      "Train: 29.58s, Test: 2.67s\n",
      "\n",
      "Epoch: 60\n",
      "Training epoch 60: Loss=1.229 Acc=55.938\n",
      "Testing epoch 60: Loss=1.173 Acc=57.860\n",
      "Saving..\n",
      "Epoch 60: 1935.51s\n",
      "Train: 29.35s, Test: 2.93s\n",
      "\n",
      "Epoch: 61\n",
      "Training epoch 61: Loss=1.229 Acc=55.788\n",
      "Testing epoch 61: Loss=1.174 Acc=57.980\n",
      "Saving..\n",
      "Epoch 61: 1968.00s\n",
      "Train: 29.76s, Test: 2.73s\n",
      "\n",
      "Epoch: 62\n",
      "Training epoch 62: Loss=1.225 Acc=56.018\n",
      "Testing epoch 62: Loss=1.171 Acc=58.100\n",
      "Saving..\n",
      "Epoch 62: 2000.30s\n",
      "Train: 29.45s, Test: 2.85s\n",
      "\n",
      "Epoch: 63\n",
      "Training epoch 63: Loss=1.224 Acc=56.172\n",
      "Testing epoch 63: Loss=1.169 Acc=58.260\n",
      "Saving..\n",
      "Epoch 63: 2032.63s\n",
      "Train: 29.56s, Test: 2.78s\n",
      "\n",
      "Epoch: 64\n",
      "Training epoch 64: Loss=1.219 Acc=56.184\n",
      "Testing epoch 64: Loss=1.166 Acc=58.270\n",
      "Saving..\n",
      "Epoch 64: 2064.79s\n",
      "Train: 29.55s, Test: 2.61s\n",
      "\n",
      "Epoch: 65\n",
      "Training epoch 65: Loss=1.217 Acc=56.244\n",
      "Testing epoch 65: Loss=1.164 Acc=58.360\n",
      "Saving..\n",
      "Epoch 65: 2097.37s\n",
      "Train: 29.50s, Test: 3.07s\n",
      "\n",
      "Epoch: 66\n",
      "Training epoch 66: Loss=1.214 Acc=56.440\n",
      "Testing epoch 66: Loss=1.165 Acc=58.330\n",
      "Epoch 66: 2129.71s\n",
      "Train: 29.68s, Test: 2.66s\n",
      "\n",
      "Epoch: 67\n",
      "Training epoch 67: Loss=1.208 Acc=56.662\n",
      "Testing epoch 67: Loss=1.161 Acc=58.550\n",
      "Saving..\n",
      "Epoch 67: 2162.03s\n",
      "Train: 29.65s, Test: 2.66s\n",
      "\n",
      "Epoch: 68\n",
      "Training epoch 68: Loss=1.211 Acc=56.562\n",
      "Testing epoch 68: Loss=1.159 Acc=58.590\n",
      "Saving..\n",
      "Epoch 68: 2194.20s\n",
      "Train: 29.38s, Test: 2.79s\n",
      "\n",
      "Epoch: 69\n",
      "Training epoch 69: Loss=1.203 Acc=56.934\n",
      "Testing epoch 69: Loss=1.158 Acc=58.620\n",
      "Saving..\n",
      "Epoch 69: 2226.71s\n",
      "Train: 29.60s, Test: 2.92s\n",
      "\n",
      "Epoch: 70\n",
      "Training epoch 70: Loss=1.207 Acc=56.594\n",
      "Testing epoch 70: Loss=1.157 Acc=58.680\n",
      "Saving..\n",
      "Epoch 70: 2259.16s\n",
      "Train: 29.70s, Test: 2.75s\n",
      "\n",
      "Epoch: 71\n",
      "Training epoch 71: Loss=1.204 Acc=56.778\n",
      "Testing epoch 71: Loss=1.154 Acc=58.850\n",
      "Saving..\n",
      "Epoch 71: 2291.53s\n",
      "Train: 29.76s, Test: 2.61s\n",
      "\n",
      "Epoch: 72\n",
      "Training epoch 72: Loss=1.199 Acc=57.046\n",
      "Testing epoch 72: Loss=1.152 Acc=58.750\n",
      "Epoch 72: 2324.01s\n",
      "Train: 29.89s, Test: 2.59s\n",
      "\n",
      "Epoch: 73\n",
      "Training epoch 73: Loss=1.197 Acc=57.210\n",
      "Testing epoch 73: Loss=1.152 Acc=58.830\n",
      "Epoch 73: 2356.29s\n",
      "Train: 29.55s, Test: 2.73s\n",
      "\n",
      "Epoch: 74\n",
      "Training epoch 74: Loss=1.198 Acc=57.096\n",
      "Testing epoch 74: Loss=1.147 Acc=58.940\n",
      "Saving..\n",
      "Epoch 74: 2388.68s\n",
      "Train: 29.72s, Test: 2.67s\n",
      "\n",
      "Epoch: 75\n",
      "Training epoch 75: Loss=1.192 Acc=57.392\n",
      "Testing epoch 75: Loss=1.148 Acc=59.080\n",
      "Saving..\n",
      "Epoch 75: 2421.07s\n",
      "Train: 29.52s, Test: 2.87s\n",
      "\n",
      "Epoch: 76\n",
      "Training epoch 76: Loss=1.193 Acc=57.150\n",
      "Testing epoch 76: Loss=1.145 Acc=59.130\n",
      "Saving..\n",
      "Epoch 76: 2453.54s\n",
      "Train: 29.85s, Test: 2.62s\n",
      "\n",
      "Epoch: 77\n",
      "Training epoch 77: Loss=1.188 Acc=57.412\n",
      "Testing epoch 77: Loss=1.144 Acc=59.140\n",
      "Saving..\n",
      "Epoch 77: 2485.49s\n",
      "Train: 29.35s, Test: 2.60s\n",
      "\n",
      "Epoch: 78\n",
      "Training epoch 78: Loss=1.192 Acc=57.228\n",
      "Testing epoch 78: Loss=1.142 Acc=59.280\n",
      "Saving..\n",
      "Epoch 78: 2517.80s\n",
      "Train: 29.47s, Test: 2.83s\n",
      "\n",
      "Epoch: 79\n",
      "Training epoch 79: Loss=1.186 Acc=57.366\n",
      "Testing epoch 79: Loss=1.140 Acc=59.030\n",
      "Epoch 79: 2550.22s\n",
      "Train: 29.72s, Test: 2.70s\n",
      "\n",
      "Epoch: 80\n",
      "Training epoch 80: Loss=1.185 Acc=57.642\n",
      "Testing epoch 80: Loss=1.138 Acc=59.270\n",
      "Epoch 80: 2582.68s\n",
      "Train: 29.61s, Test: 2.85s\n",
      "\n",
      "Epoch: 81\n",
      "Training epoch 81: Loss=1.185 Acc=57.468\n",
      "Testing epoch 81: Loss=1.137 Acc=59.250\n",
      "Epoch 81: 2614.94s\n",
      "Train: 29.67s, Test: 2.60s\n",
      "\n",
      "Epoch: 82\n",
      "Training epoch 82: Loss=1.180 Acc=57.940\n",
      "Testing epoch 82: Loss=1.135 Acc=59.450\n",
      "Saving..\n",
      "Epoch 82: 2647.53s\n",
      "Train: 30.09s, Test: 2.49s\n",
      "\n",
      "Epoch: 83\n",
      "Training epoch 83: Loss=1.180 Acc=57.728\n",
      "Testing epoch 83: Loss=1.134 Acc=59.490\n",
      "Saving..\n",
      "Epoch 83: 2680.03s\n",
      "Train: 29.94s, Test: 2.55s\n",
      "\n",
      "Epoch: 84\n",
      "Training epoch 84: Loss=1.180 Acc=57.718\n",
      "Testing epoch 84: Loss=1.131 Acc=59.490\n",
      "Epoch 84: 2712.67s\n",
      "Train: 30.20s, Test: 2.44s\n",
      "\n",
      "Epoch: 85\n",
      "Training epoch 85: Loss=1.175 Acc=57.986\n",
      "Testing epoch 85: Loss=1.131 Acc=59.560\n",
      "Saving..\n",
      "Epoch 85: 2745.31s\n",
      "Train: 30.26s, Test: 2.38s\n",
      "\n",
      "Epoch: 86\n",
      "Training epoch 86: Loss=1.176 Acc=57.932\n",
      "Testing epoch 86: Loss=1.129 Acc=59.620\n",
      "Saving..\n",
      "Epoch 86: 2778.14s\n",
      "Train: 30.32s, Test: 2.51s\n",
      "\n",
      "Epoch: 87\n",
      "Training epoch 87: Loss=1.173 Acc=58.090\n",
      "Testing epoch 87: Loss=1.130 Acc=59.680\n",
      "Saving..\n",
      "Epoch 87: 2810.90s\n",
      "Train: 30.08s, Test: 2.68s\n",
      "\n",
      "Epoch: 88\n",
      "Training epoch 88: Loss=1.168 Acc=57.804\n",
      "Testing epoch 88: Loss=1.127 Acc=59.910\n",
      "Saving..\n",
      "Epoch 88: 2843.32s\n",
      "Train: 29.63s, Test: 2.78s\n",
      "\n",
      "Epoch: 89\n",
      "Training epoch 89: Loss=1.163 Acc=58.122\n",
      "Testing epoch 89: Loss=1.124 Acc=59.840\n",
      "Epoch 89: 2875.54s\n",
      "Train: 29.46s, Test: 2.77s\n",
      "\n",
      "Epoch: 90\n",
      "Training epoch 90: Loss=1.163 Acc=58.392\n",
      "Testing epoch 90: Loss=1.122 Acc=59.780\n",
      "Epoch 90: 2907.78s\n",
      "Train: 29.59s, Test: 2.64s\n",
      "\n",
      "Epoch: 91\n",
      "Training epoch 91: Loss=1.162 Acc=58.476\n",
      "Testing epoch 91: Loss=1.122 Acc=59.780\n",
      "Epoch 91: 2940.21s\n",
      "Train: 29.73s, Test: 2.71s\n",
      "\n",
      "Epoch: 92\n",
      "Training epoch 92: Loss=1.163 Acc=58.318\n",
      "Testing epoch 92: Loss=1.120 Acc=59.990\n",
      "Saving..\n",
      "Epoch 92: 2972.49s\n",
      "Train: 29.51s, Test: 2.77s\n",
      "\n",
      "Epoch: 93\n",
      "Training epoch 93: Loss=1.157 Acc=58.534\n",
      "Testing epoch 93: Loss=1.118 Acc=60.040\n",
      "Saving..\n",
      "Epoch 93: 3004.72s\n",
      "Train: 29.51s, Test: 2.72s\n",
      "\n",
      "Epoch: 94\n",
      "Training epoch 94: Loss=1.159 Acc=58.386\n",
      "Testing epoch 94: Loss=1.117 Acc=59.980\n",
      "Epoch 94: 3037.33s\n",
      "Train: 29.78s, Test: 2.83s\n",
      "\n",
      "Epoch: 95\n",
      "Training epoch 95: Loss=1.160 Acc=58.470\n",
      "Testing epoch 95: Loss=1.116 Acc=60.180\n",
      "Saving..\n",
      "Epoch 95: 3069.68s\n",
      "Train: 29.51s, Test: 2.84s\n",
      "\n",
      "Epoch: 96\n",
      "Training epoch 96: Loss=1.155 Acc=58.630\n",
      "Testing epoch 96: Loss=1.115 Acc=60.100\n",
      "Epoch 96: 3101.93s\n",
      "Train: 29.44s, Test: 2.81s\n",
      "\n",
      "Epoch: 97\n",
      "Training epoch 97: Loss=1.155 Acc=58.740\n",
      "Testing epoch 97: Loss=1.114 Acc=60.050\n",
      "Epoch 97: 3133.97s\n",
      "Train: 29.38s, Test: 2.66s\n",
      "\n",
      "Epoch: 98\n",
      "Training epoch 98: Loss=1.155 Acc=58.598\n",
      "Testing epoch 98: Loss=1.112 Acc=60.340\n",
      "Saving..\n",
      "Epoch 98: 3166.03s\n",
      "Train: 29.23s, Test: 2.83s\n",
      "\n",
      "Epoch: 99\n",
      "Training epoch 99: Loss=1.149 Acc=58.946\n",
      "Testing epoch 99: Loss=1.110 Acc=60.350\n",
      "Saving..\n",
      "Epoch 99: 3198.32s\n",
      "Train: 29.59s, Test: 2.70s\n",
      "\n",
      "Epoch: 100\n",
      "Training epoch 100: Loss=1.148 Acc=59.060\n",
      "Testing epoch 100: Loss=1.110 Acc=60.450\n",
      "Saving..\n",
      "Epoch 100: 3230.68s\n",
      "Train: 29.58s, Test: 2.77s\n",
      "\n",
      "Epoch: 101\n",
      "Training epoch 101: Loss=1.147 Acc=59.198\n",
      "Testing epoch 101: Loss=1.108 Acc=60.580\n",
      "Saving..\n",
      "Epoch 101: 3262.61s\n",
      "Train: 29.32s, Test: 2.62s\n",
      "\n",
      "Epoch: 102\n",
      "Training epoch 102: Loss=1.149 Acc=58.720\n",
      "Testing epoch 102: Loss=1.107 Acc=60.470\n",
      "Epoch 102: 3294.70s\n",
      "Train: 29.40s, Test: 2.68s\n",
      "\n",
      "Epoch: 103\n",
      "Training epoch 103: Loss=1.143 Acc=59.160\n",
      "Testing epoch 103: Loss=1.105 Acc=60.440\n",
      "Epoch 103: 3327.00s\n",
      "Train: 29.50s, Test: 2.80s\n",
      "\n",
      "Epoch: 104\n",
      "Training epoch 104: Loss=1.143 Acc=59.190\n",
      "Testing epoch 104: Loss=1.104 Acc=60.390\n",
      "Epoch 104: 3359.07s\n",
      "Train: 29.55s, Test: 2.52s\n",
      "\n",
      "Epoch: 105\n",
      "Training epoch 105: Loss=1.139 Acc=59.262\n",
      "Testing epoch 105: Loss=1.103 Acc=60.730\n",
      "Saving..\n",
      "Epoch 105: 3391.44s\n",
      "Train: 29.60s, Test: 2.78s\n",
      "\n",
      "Epoch: 106\n",
      "Training epoch 106: Loss=1.143 Acc=58.998\n",
      "Testing epoch 106: Loss=1.102 Acc=60.770\n",
      "Saving..\n",
      "Epoch 106: 3423.95s\n",
      "Train: 29.64s, Test: 2.87s\n",
      "\n",
      "Epoch: 107\n",
      "Training epoch 107: Loss=1.139 Acc=59.436\n",
      "Testing epoch 107: Loss=1.100 Acc=60.840\n",
      "Saving..\n",
      "Epoch 107: 3456.33s\n",
      "Train: 29.74s, Test: 2.64s\n",
      "\n",
      "Epoch: 108\n",
      "Training epoch 108: Loss=1.134 Acc=59.514\n",
      "Testing epoch 108: Loss=1.100 Acc=60.790\n",
      "Epoch 108: 3488.56s\n",
      "Train: 29.56s, Test: 2.67s\n",
      "\n",
      "Epoch: 109\n",
      "Training epoch 109: Loss=1.135 Acc=59.616\n",
      "Testing epoch 109: Loss=1.097 Acc=60.920\n",
      "Saving..\n",
      "Epoch 109: 3520.99s\n",
      "Train: 29.69s, Test: 2.75s\n",
      "\n",
      "Epoch: 110\n",
      "Training epoch 110: Loss=1.135 Acc=59.424\n",
      "Testing epoch 110: Loss=1.097 Acc=60.970\n",
      "Saving..\n",
      "Epoch 110: 3553.37s\n",
      "Train: 29.64s, Test: 2.74s\n",
      "\n",
      "Epoch: 111\n",
      "Training epoch 111: Loss=1.132 Acc=59.462\n",
      "Testing epoch 111: Loss=1.095 Acc=60.990\n",
      "Saving..\n",
      "Epoch 111: 3585.69s\n",
      "Train: 29.62s, Test: 2.70s\n",
      "\n",
      "Epoch: 112\n",
      "Training epoch 112: Loss=1.129 Acc=59.704\n",
      "Testing epoch 112: Loss=1.095 Acc=61.090\n",
      "Saving..\n",
      "Epoch 112: 3618.20s\n",
      "Train: 29.65s, Test: 2.86s\n",
      "\n",
      "Epoch: 113\n",
      "Training epoch 113: Loss=1.129 Acc=59.742\n",
      "Testing epoch 113: Loss=1.094 Acc=60.990\n",
      "Epoch 113: 3650.48s\n",
      "Train: 29.74s, Test: 2.54s\n",
      "\n",
      "Epoch: 114\n",
      "Training epoch 114: Loss=1.127 Acc=59.848\n",
      "Testing epoch 114: Loss=1.093 Acc=61.060\n",
      "Epoch 114: 3682.93s\n",
      "Train: 29.95s, Test: 2.50s\n",
      "\n",
      "Epoch: 115\n",
      "Training epoch 115: Loss=1.127 Acc=59.878\n",
      "Testing epoch 115: Loss=1.091 Acc=61.080\n",
      "Epoch 115: 3715.64s\n",
      "Train: 30.30s, Test: 2.41s\n",
      "\n",
      "Epoch: 116\n",
      "Training epoch 116: Loss=1.127 Acc=59.988\n",
      "Testing epoch 116: Loss=1.092 Acc=61.170\n",
      "Saving..\n",
      "Epoch 116: 3748.56s\n",
      "Train: 30.32s, Test: 2.60s\n",
      "\n",
      "Epoch: 117\n",
      "Training epoch 117: Loss=1.124 Acc=60.002\n",
      "Testing epoch 117: Loss=1.088 Acc=61.200\n",
      "Saving..\n",
      "Epoch 117: 3781.55s\n",
      "Train: 30.25s, Test: 2.74s\n",
      "\n",
      "Epoch: 118\n",
      "Training epoch 118: Loss=1.125 Acc=59.892\n",
      "Testing epoch 118: Loss=1.089 Acc=61.280\n",
      "Saving..\n",
      "Epoch 118: 3813.77s\n",
      "Train: 29.58s, Test: 2.64s\n",
      "\n",
      "Epoch: 119\n",
      "Training epoch 119: Loss=1.122 Acc=59.934\n",
      "Testing epoch 119: Loss=1.087 Acc=61.530\n",
      "Saving..\n",
      "Epoch 119: 3846.18s\n",
      "Train: 29.63s, Test: 2.78s\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "# parser.add_argument('--resume', '-r', action='store_true',\n",
    "#                     help='resume from checkpoint')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "Learning_rate = 0.0001\n",
    "Resume = False\n",
    "Optimizer = 'adagrad'  # sgd, sgdn, adagrad, adadelta or adam\n",
    "Batch_size = 128\n",
    "\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=Batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if Resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.SGD(net.parameters(), lr=Learning_rate,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "if Optimizer == 'sgdn':\n",
    "    optimizer = optim.SGD(net.parameters(), lr=Learning_rate,\n",
    "                    momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "elif Optimizer == 'adagrad':\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=Learning_rate,\n",
    "                              weight_decay=5e-4)\n",
    "elif Optimizer == 'adadelta':\n",
    "    optimizer = optim.Adadelta(net.parameters(), lr=Learning_rate,\n",
    "                               weight_decay=5e-4)\n",
    "elif Optimizer == 'adam':\n",
    "    optimizer = optim.Adam(net.parameters(), lr=Learning_rate,\n",
    "                           weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "torchsummary.summary(net, (3, 32, 32))\n",
    "\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_training_time = 0\n",
    "    time1 = torch.cuda.Event(enable_timing=True)\n",
    "    time2 = torch.cuda.Event(enable_timing=True)\n",
    "    time1.record()\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        time2.record()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        total_training_time += time1.elapsed_time(time2)\n",
    "        \n",
    "    avg_loss = train_loss/total\n",
    "    acc = 100.*correct/total\n",
    "    print('Training epoch %d: Loss=%.3f Acc=%.3f' %\n",
    "          (epoch, avg_loss, acc))\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    avg_loss = test_loss/total\n",
    "    acc = 100.*correct/total\n",
    "    print('Testing epoch %d: Loss=%.3f Acc=%.3f' %\n",
    "          (epoch, avg_loss, acc))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "filename = Optimizer + '_' + str(Batch_size) + '_' + str(Learning_rate) + '_dropout.csv'\n",
    "file = open(filename, 'w')\n",
    "file.write('train_avg_loss, train_acc, test_avg_loss, test_acc, train_time, test_time\\n')\n",
    "Start_time = time.perf_counter()\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "for epoch in range(start_epoch, start_epoch+120):\n",
    "    time1 = time.perf_counter()\n",
    "    train_avg_loss, train_acc = train(epoch)\n",
    "    time2 = time.perf_counter()\n",
    "    test_avg_loss, test_acc = test(epoch)\n",
    "    Cur_time = time.perf_counter()\n",
    "    # scheduler.step()\n",
    "    train_acc_history.append(train_acc)\n",
    "    test_acc_history.append(test_acc)\n",
    "    print('Epoch %d: %.2fs' % (epoch, Cur_time - Start_time))\n",
    "    print('Train: %.2fs, Test: %.2fs' % (time2 - time1, Cur_time - time2))\n",
    "    file.write('%.3f, %.3f, %.3f, %.3f, %.2f, %.2f\\n' %\n",
    "               (train_avg_loss, train_acc, test_avg_loss, test_acc,\n",
    "                time2 - time1, Cur_time - time2))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c68f0b31-f395-46c9-876c-a07fb748e04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc0617ada00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(120),train_acc_history,'-',linewidth=3,label='Train accuracy')\n",
    "plt.plot(range(120),test_acc_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53047b09-39c3-40e5-b52a-212ad02d8adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
